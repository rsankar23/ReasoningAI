{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Q9O_I6lVWfr"
   },
   "source": [
    "### Install requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If8cy3B3VhKD",
    "outputId": "332cbea0-1601-4320-a4e9-d68591b10c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ReasoningAI'...\n",
      "remote: Enumerating objects: 236, done.\u001B[K\n",
      "remote: Counting objects: 100% (236/236), done.\u001B[K\n",
      "remote: Compressing objects: 100% (164/164), done.\u001B[K\n",
      "remote: Total 236 (delta 135), reused 142 (delta 67), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (236/236), 71.29 KiB | 1.45 MiB/s, done.\n",
      "Resolving deltas: 100% (135/135), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rsankar23/ReasoningAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWpuKAUnVi8z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/ReasoningAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuSfcNKYsvJC",
    "outputId": "44d3b0aa-c3e4-4324-db7c-67cb5a3716e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 1)) (2.6.1)\n",
      "Collecting aiohttp==3.11.16 (from -r /content/ReasoningAI/requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: altair==5.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 4)) (5.5.0)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 6)) (4.9.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 7)) (25.3.0)\n",
      "Collecting beautifulsoup4==4.13.3 (from -r /content/ReasoningAI/requirements.txt (line 8))\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: blinker==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 9)) (1.9.0)\n",
      "Requirement already satisfied: cachetools==5.5.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 10)) (5.5.2)\n",
      "Collecting certifi==2025.1.31 (from -r /content/ReasoningAI/requirements.txt (line 11))\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting charset-normalizer==3.4.1 (from -r /content/ReasoningAI/requirements.txt (line 12))\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 13)) (8.1.8)\n",
      "Collecting dataclasses-json==0.6.7 (from -r /content/ReasoningAI/requirements.txt (line 14))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock==3.18.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 15)) (3.18.0)\n",
      "Collecting frozenlist==1.5.0 (from -r /content/ReasoningAI/requirements.txt (line 16))\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: fsspec==2025.3.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 17)) (2025.3.2)\n",
      "Requirement already satisfied: gitdb==4.0.12 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 18)) (4.0.12)\n",
      "Requirement already satisfied: GitPython==3.1.44 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 19)) (3.1.44)\n",
      "Collecting h11==0.14.0 (from -r /content/ReasoningAI/requirements.txt (line 20))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httpcore==1.0.7 (from -r /content/ReasoningAI/requirements.txt (line 21))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 22)) (0.28.1)\n",
      "Collecting httpx-sse==0.4.0 (from -r /content/ReasoningAI/requirements.txt (line 23))\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting huggingface-hub==0.30.1 (from -r /content/ReasoningAI/requirements.txt (line 24))\n",
      "  Downloading huggingface_hub-0.30.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 25)) (3.10)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 26)) (3.1.6)\n",
      "Collecting joblib==1.4.2 (from -r /content/ReasoningAI/requirements.txt (line 27))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: jsonpatch==1.33 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 28)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 29)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 30)) (4.23.0)\n",
      "Collecting jsonschema-specifications==2024.10.1 (from -r /content/ReasoningAI/requirements.txt (line 31))\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langchain==0.3.25 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 32)) (0.3.25)\n",
      "Collecting langchain-anthropic==0.3.12 (from -r /content/ReasoningAI/requirements.txt (line 33))\n",
      "  Downloading langchain_anthropic-0.3.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-openai==0.3.16 (from -r /content/ReasoningAI/requirements.txt (line 34))\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting anthropic==0.50.0 (from -r /content/ReasoningAI/requirements.txt (line 35))\n",
      "  Downloading anthropic-0.50.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting openai==1.76.0 (from -r /content/ReasoningAI/requirements.txt (line 36))\n",
      "  Downloading openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain-community==0.3.21 (from -r /content/ReasoningAI/requirements.txt (line 37))\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core==0.3.58 (from -r /content/ReasoningAI/requirements.txt (line 38))\n",
      "  Downloading langchain_core-0.3.58-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-huggingface==0.1.2 (from -r /content/ReasoningAI/requirements.txt (line 39))\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain-tavily==0.1.5 (from -r /content/ReasoningAI/requirements.txt (line 40))\n",
      "  Downloading langchain_tavily-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 41)) (0.3.8)\n",
      "Collecting langgraph==0.3.25 (from -r /content/ReasoningAI/requirements.txt (line 42))\n",
      "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting langgraph-checkpoint==2.0.24 (from -r /content/ReasoningAI/requirements.txt (line 43))\n",
      "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt==0.1.8 (from -r /content/ReasoningAI/requirements.txt (line 44))\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk==0.1.61 (from -r /content/ReasoningAI/requirements.txt (line 45))\n",
      "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith==0.3.24 (from -r /content/ReasoningAI/requirements.txt (line 46))\n",
      "  Downloading langsmith-0.3.24-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 47)) (3.0.2)\n",
      "Collecting marshmallow==3.26.1 (from -r /content/ReasoningAI/requirements.txt (line 48))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 49)) (1.3.0)\n",
      "Collecting multidict==6.3.2 (from -r /content/ReasoningAI/requirements.txt (line 50))\n",
      "  Downloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting mypy==1.15.0 (from -r /content/ReasoningAI/requirements.txt (line 51))\n",
      "  Downloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting mypy-extensions==1.0.0 (from -r /content/ReasoningAI/requirements.txt (line 52))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting narwhals==1.33.0 (from -r /content/ReasoningAI/requirements.txt (line 53))\n",
      "  Downloading narwhals-1.33.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: networkx==3.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 54)) (3.4.2)\n",
      "Collecting numpy==2.2.4 (from -r /content/ReasoningAI/requirements.txt (line 55))\n",
      "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.0/62.0 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting orjson==3.10.16 (from -r /content/ReasoningAI/requirements.txt (line 56))\n",
      "  Downloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m41.8/41.8 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting ormsgpack==1.9.1 (from -r /content/ReasoningAI/requirements.txt (line 57))\n",
      "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.5/43.5 kB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 58)) (24.2)\n",
      "Collecting pandas==2.2.3 (from -r /content/ReasoningAI/requirements.txt (line 59))\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.9/89.9 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pillow==11.1.0 (from -r /content/ReasoningAI/requirements.txt (line 60))\n",
      "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: propcache==0.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 61)) (0.3.1)\n",
      "Requirement already satisfied: protobuf==5.29.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 62)) (5.29.4)\n",
      "Collecting pyarrow==19.0.1 (from -r /content/ReasoningAI/requirements.txt (line 63))\n",
      "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pydantic==2.11.2 (from -r /content/ReasoningAI/requirements.txt (line 64))\n",
      "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m64.7/64.7 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pydantic-settings==2.8.1 (from -r /content/ReasoningAI/requirements.txt (line 65))\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pydantic_core==2.33.1 (from -r /content/ReasoningAI/requirements.txt (line 66))\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pydeck==0.9.1 (from -r /content/ReasoningAI/requirements.txt (line 67))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 68)) (2.9.0.post0)\n",
      "Collecting python-dotenv==1.1.0 (from -r /content/ReasoningAI/requirements.txt (line 69))\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pytz==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 70)) (2025.2)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 71)) (6.0.2)\n",
      "Requirement already satisfied: referencing==0.36.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 72)) (0.36.2)\n",
      "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 73)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 74)) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 75)) (1.0.0)\n",
      "Requirement already satisfied: rpds-py==0.24.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 76)) (0.24.0)\n",
      "Requirement already satisfied: safetensors==0.5.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 77)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 78)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 79)) (1.15.2)\n",
      "Collecting sentence-transformers==4.0.2 (from -r /content/ReasoningAI/requirements.txt (line 80))\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting setuptools==78.1.0 (from -r /content/ReasoningAI/requirements.txt (line 81))\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six==1.17.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 82)) (1.17.0)\n",
      "Requirement already satisfied: smmap==5.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 83)) (5.0.2)\n",
      "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 84)) (1.3.1)\n",
      "Collecting soupsieve==2.6 (from -r /content/ReasoningAI/requirements.txt (line 85))\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.40 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 86)) (2.0.40)\n",
      "Collecting streamlit==1.44.1 (from -r /content/ReasoningAI/requirements.txt (line 87))\n",
      "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 88)) (1.13.1)\n",
      "Requirement already satisfied: tenacity==9.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 89)) (9.1.2)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 90)) (3.6.0)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 91)) (0.21.1)\n",
      "Requirement already satisfied: toml==0.10.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 92)) (0.10.2)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 93)) (2.6.0+cu124)\n",
      "Requirement already satisfied: tornado==6.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 94)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 95)) (4.67.1)\n",
      "Collecting transformers==4.50.3 (from -r /content/ReasoningAI/requirements.txt (line 96))\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting typing-inspect==0.9.0 (from -r /content/ReasoningAI/requirements.txt (line 97))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 98)) (0.4.0)\n",
      "Collecting typing_extensions==4.13.1 (from -r /content/ReasoningAI/requirements.txt (line 99))\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: tzdata==2025.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 100)) (2025.2)\n",
      "Collecting urllib3==2.3.0 (from -r /content/ReasoningAI/requirements.txt (line 101))\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting watchdog==6.0.0 (from -r /content/ReasoningAI/requirements.txt (line 102))\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.3/44.3 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting wikipedia==1.4.0 (from -r /content/ReasoningAI/requirements.txt (line 103))\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: xxhash==3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 104)) (3.5.0)\n",
      "Collecting yarl==1.18.3 (from -r /content/ReasoningAI/requirements.txt (line 105))\n",
      "  Downloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m69.2/69.2 kB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: zstandard==0.23.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 106)) (0.23.0)\n",
      "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/ReasoningAI/requirements.txt (line 107)) (3.10.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.16->-r /content/ReasoningAI/requirements.txt (line 34)) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic==0.50.0->-r /content/ReasoningAI/requirements.txt (line 35)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic==0.50.0->-r /content/ReasoningAI/requirements.txt (line 35)) (0.9.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy==2.0.40->-r /content/ReasoningAI/requirements.txt (line 86)) (3.2.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r /content/ReasoningAI/requirements.txt (line 93)) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r /content/ReasoningAI/requirements.txt (line 107)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r /content/ReasoningAI/requirements.txt (line 107)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r /content/ReasoningAI/requirements.txt (line 107)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r /content/ReasoningAI/requirements.txt (line 107)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5.0->-r /content/ReasoningAI/requirements.txt (line 107)) (3.2.3)\n",
      "\u001B[33mWARNING: The candidate selected for download or install is a yanked version: 'multidict' candidate (version 6.3.2 at https://files.pythonhosted.org/packages/24/a9/286756a1afb8648772de851f8f39d2dd4076506f0c0fc2b751259fcbf0dd/multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/multidict/) (requires-python:>=3.9))\n",
      "Reason for being yanked: Memory leak: https://github.com/aio-libs/multidict/issues/1131#issuecomment-2787514071\u001B[0m\u001B[33m\n",
      "\u001B[0mDownloading aiohttp-3.11.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m33.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m186.0/186.0 kB\u001B[0m \u001B[31m13.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m16.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.9/143.9 kB\u001B[0m \u001B[31m14.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m274.9/274.9 kB\u001B[0m \u001B[31m24.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.6/78.6 kB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading huggingface_hub-0.30.1-py3-none-any.whl (481 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m481.2/481.2 kB\u001B[0m \u001B[31m36.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m301.8/301.8 kB\u001B[0m \u001B[31m27.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading langchain_anthropic-0.3.12-py3-none-any.whl (25 kB)\n",
      "Downloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.8/62.8 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading anthropic-0.50.0-py3-none-any.whl (245 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m245.3/245.3 kB\u001B[0m \u001B[31m21.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m661.2/661.2 kB\u001B[0m \u001B[31m49.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m86.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_core-0.3.58-py3-none-any.whl (437 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m437.6/437.6 kB\u001B[0m \u001B[31m33.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading langchain_tavily-0.1.5-py3-none-any.whl (14 kB)\n",
      "Downloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m142.4/142.4 kB\u001B[0m \u001B[31m13.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.0/42.0 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m47.2/47.2 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading langsmith-0.3.24-py3-none-any.whl (352 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m352.8/352.8 kB\u001B[0m \u001B[31m5.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.9/50.9 kB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multidict-6.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (238 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m238.5/238.5 kB\u001B[0m \u001B[31m23.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mypy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.3/12.3 MB\u001B[0m \u001B[31m101.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading narwhals-1.33.0-py3-none-any.whl (322 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m322.8/322.8 kB\u001B[0m \u001B[31m27.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.4/16.4 MB\u001B[0m \u001B[31m110.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading orjson-3.10.16-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m132.8/132.8 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m223.6/223.6 kB\u001B[0m \u001B[31m18.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m118.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.5/4.5 MB\u001B[0m \u001B[31m108.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.1/42.1 MB\u001B[0m \u001B[31m57.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m443.3/443.3 kB\u001B[0m \u001B[31m32.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m82.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.9/6.9 MB\u001B[0m \u001B[31m125.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m340.6/340.6 kB\u001B[0m \u001B[31m26.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m69.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.8/9.8 MB\u001B[0m \u001B[31m114.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.2/10.2 MB\u001B[0m \u001B[31m126.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.7/45.7 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.4/128.4 kB\u001B[0m \u001B[31m10.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.1/79.1 kB\u001B[0m \u001B[31m7.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading yarl-1.18.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m344.1/344.1 kB\u001B[0m \u001B[31m27.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m363.4/363.4 MB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.8/13.8 MB\u001B[0m \u001B[31m127.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.6/24.6 MB\u001B[0m \u001B[31m99.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m883.7/883.7 kB\u001B[0m \u001B[31m65.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m664.8/664.8 MB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.5/211.5 MB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m56.3/56.3 MB\u001B[0m \u001B[31m38.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.9/127.9 MB\u001B[0m \u001B[31m18.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m207.5/207.5 MB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m21.1/21.1 MB\u001B[0m \u001B[31m87.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=143cc10e40a8a0ea8ddf60743bbafa9731cf0aa3d6dfdacbdae0335df3cbd984\n",
      "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: watchdog, urllib3, typing_extensions, soupsieve, setuptools, python-dotenv, pyarrow, pillow, ormsgpack, orjson, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, narwhals, mypy-extensions, multidict, marshmallow, joblib, httpx-sse, h11, frozenlist, charset-normalizer, certifi, yarl, typing-inspect, pydeck, pydantic_core, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mypy, httpcore, beautifulsoup4, wikipedia, pydantic, nvidia-cusolver-cu12, jsonschema-specifications, huggingface-hub, dataclasses-json, aiohttp, pydantic-settings, openai, langsmith, langgraph-sdk, anthropic, transformers, langchain-core, streamlit, sentence-transformers, langgraph-checkpoint, langchain-openai, langchain-anthropic, langgraph-prebuilt, langchain-huggingface, langgraph, langchain-tavily, langchain-community\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.4.0\n",
      "    Uninstalling urllib3-2.4.0:\n",
      "      Successfully uninstalled urllib3-2.4.0\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "  Attempting uninstall: soupsieve\n",
      "    Found existing installation: soupsieve 2.7\n",
      "    Uninstalling soupsieve-2.7:\n",
      "      Successfully uninstalled soupsieve-2.7\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.2.0\n",
      "    Uninstalling setuptools-75.2.0:\n",
      "      Successfully uninstalled setuptools-75.2.0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 18.1.0\n",
      "    Uninstalling pyarrow-18.1.0:\n",
      "      Successfully uninstalled pyarrow-18.1.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.2.1\n",
      "    Uninstalling pillow-11.2.1:\n",
      "      Successfully uninstalled pillow-11.2.1\n",
      "  Attempting uninstall: orjson\n",
      "    Found existing installation: orjson 3.10.18\n",
      "    Uninstalling orjson-3.10.18:\n",
      "      Successfully uninstalled orjson-3.10.18\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: narwhals\n",
      "    Found existing installation: narwhals 1.38.0\n",
      "    Uninstalling narwhals-1.38.0:\n",
      "      Successfully uninstalled narwhals-1.38.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.4.3\n",
      "    Uninstalling multidict-6.4.3:\n",
      "      Successfully uninstalled multidict-6.4.3\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.5.0\n",
      "    Uninstalling joblib-1.5.0:\n",
      "      Successfully uninstalled joblib-1.5.0\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.16.0\n",
      "    Uninstalling h11-0.16.0:\n",
      "      Successfully uninstalled h11-0.16.0\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.6.0\n",
      "    Uninstalling frozenlist-1.6.0:\n",
      "      Successfully uninstalled frozenlist-1.6.0\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.2\n",
      "    Uninstalling charset-normalizer-3.4.2:\n",
      "      Successfully uninstalled charset-normalizer-3.4.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.4.26\n",
      "    Uninstalling certifi-2025.4.26:\n",
      "      Successfully uninstalled certifi-2025.4.26\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.20.0\n",
      "    Uninstalling yarl-1.20.0:\n",
      "      Successfully uninstalled yarl-1.20.0\n",
      "  Attempting uninstall: pydantic_core\n",
      "    Found existing installation: pydantic_core 2.33.2\n",
      "    Uninstalling pydantic_core-2.33.2:\n",
      "      Successfully uninstalled pydantic_core-2.33.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.9\n",
      "    Uninstalling httpcore-1.0.9:\n",
      "      Successfully uninstalled httpcore-1.0.9\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.13.4\n",
      "    Uninstalling beautifulsoup4-4.13.4:\n",
      "      Successfully uninstalled beautifulsoup4-4.13.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.11.4\n",
      "    Uninstalling pydantic-2.11.4:\n",
      "      Successfully uninstalled pydantic-2.11.4\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2025.4.1\n",
      "    Uninstalling jsonschema-specifications-2025.4.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2025.4.1\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.31.1\n",
      "    Uninstalling huggingface-hub-0.31.1:\n",
      "      Successfully uninstalled huggingface-hub-0.31.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.15\n",
      "    Uninstalling aiohttp-3.11.15:\n",
      "      Successfully uninstalled aiohttp-3.11.15\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.77.0\n",
      "    Uninstalling openai-1.77.0:\n",
      "      Successfully uninstalled openai-1.77.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.42\n",
      "    Uninstalling langsmith-0.3.42:\n",
      "      Successfully uninstalled langsmith-0.3.42\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.59\n",
      "    Uninstalling langchain-core-0.3.59:\n",
      "      Successfully uninstalled langchain-core-0.3.59\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 4.1.0\n",
      "    Uninstalling sentence-transformers-4.1.0:\n",
      "      Successfully uninstalled sentence-transformers-4.1.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed aiohttp-3.11.16 anthropic-0.50.0 beautifulsoup4-4.13.3 certifi-2025.1.31 charset-normalizer-3.4.1 dataclasses-json-0.6.7 frozenlist-1.5.0 h11-0.14.0 httpcore-1.0.7 httpx-sse-0.4.0 huggingface-hub-0.30.1 joblib-1.4.2 jsonschema-specifications-2024.10.1 langchain-anthropic-0.3.12 langchain-community-0.3.21 langchain-core-0.3.58 langchain-huggingface-0.1.2 langchain-openai-0.3.16 langchain-tavily-0.1.5 langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 langsmith-0.3.24 marshmallow-3.26.1 multidict-6.3.2 mypy-1.15.0 mypy-extensions-1.0.0 narwhals-1.33.0 numpy-2.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-1.76.0 orjson-3.10.16 ormsgpack-1.9.1 pandas-2.2.3 pillow-11.1.0 pyarrow-19.0.1 pydantic-2.11.2 pydantic-settings-2.8.1 pydantic_core-2.33.1 pydeck-0.9.1 python-dotenv-1.1.0 sentence-transformers-4.0.2 setuptools-78.1.0 soupsieve-2.6 streamlit-1.44.1 transformers-4.50.3 typing-inspect-0.9.0 typing_extensions-4.13.1 urllib3-2.3.0 watchdog-6.0.0 wikipedia-1.4.0 yarl-1.18.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "0ead399a6277452b84b3c8004fc8fe8a",
       "pip_warning": {
        "packages": [
         "PIL",
         "_distutils_hack",
         "certifi",
         "pkg_resources"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -r /content/ReasoningAI/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gH_mSj0sNig"
   },
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egesnC7oqg-3"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339,
     "referenced_widgets": [
      "ffbab6e7401e441fa0df143ac971266e",
      "4193eb1fd897470c94bcac1d3f396eb6",
      "b6b8019ccb4642b7bd830cd4f0aa6b60",
      "922bf9238db6488c9db352836e59ce78",
      "ab32ccea70844ebe935cafa934042dc0",
      "ebb31c74fbe24b469006ac24ecf26a77",
      "66ac81ee59214838b5bb07ad1fe949ca",
      "8f7c5df453224149ab470ece1273f8a2",
      "f6b23560f59e452c9b31bae652e20f0e",
      "965b25fe627f4562928835e7c3db8486",
      "b7ed6631145943d6a4af7107c43e54d5",
      "9c754fbec3dc4838934a9805fa0ac524",
      "7044eb78fd00424d8563eb9eac181479",
      "ed883e6363ed4a11b7fef5dfe57cbdbf",
      "c9730f77a54e43b88770cec4b0387d2c",
      "546383cf6ab345a5bd903ac3b6214330",
      "10acb10ba3704934a393d36832eef5e1",
      "1aa27883bacb4900870f0c2e87251a9e",
      "dca996d4075a40a0a96fa0c52ba65db7",
      "f7ae1e526cda4076a2038e46d612607e",
      "d5fc4634281647be8374435e9ae5518a",
      "b1e987f1fa334900a11d433aaf897070",
      "4a56ff10e48042389c93be00559a51ab",
      "9623676312454e378fbd33d0ab120c68",
      "219e067868de41b49ce32c6639b8b31f",
      "b690f556381f42ad81389342048598ac",
      "03ec30550c29470a83120291b300d051",
      "947582de69d84d66bea8c0dfcb5fac63",
      "77831da0381247b5948c9f89d07b6356",
      "f7a36135f77342228e6cda70745297e8",
      "261ad2f66c6441c3abd824d72ddb001a",
      "de8d1f32357142259e338db0932a5264",
      "fe2adf161a2d4f63a75dc984e5813b42",
      "64529799d6af434a92a7a874fd4eaeec",
      "df69d050eb66401480ed4682b108750a",
      "250d6044e72a4d0fa05182140f691f4c",
      "df8c5805cc714ceeb17e57cd751d69b7",
      "aacede47dccb4b599e23ea17c7f5a60f",
      "3fbef0af0dd945b296f6097a26a5b9b3",
      "b643418c54074ed5bf4530411873a92e",
      "a3cef69820ce47b8a706fea0b912f0ef",
      "36eefd8844e14105b9836d0acbe995ee",
      "74bc569a765e4420a9a7ffc5fac926d2",
      "0e4800b9dc54400db252c005fff31cd2",
      "ad1ed2a7b6d24443a67c885d911ff3aa",
      "9110260092714ac680b2914b157a01c3",
      "a17ef2fabafa4727bb3b04ab22f61cf7",
      "22957721b1d0426eb66003b3db4ae473",
      "e56e53f1657544589046df1a22c28a51",
      "836f417e8282420d974cece602d28bcf",
      "d857aee4d742474c866e73dc113c2c9e",
      "e25ddd35e25944599127aebdc31659cb",
      "4971cca062084016b59f682c3511b22c",
      "efb49102d9b046a68d33676c74972cc5",
      "d50d966a30d14e5ebac9611313e78b83",
      "fd5fc14894d04b18ac6c13d420d9ad80",
      "edcb7ae4fd7e43f4bae7b7f020594f79",
      "6a0a797621314b28a7bbb52c2294f511",
      "3cadd5dda7ac4070b30eefa05eca8c89",
      "35c6637b455240ec83e5aaa5034dd357",
      "ce02ac3e2db74a99a1f35fb552cb3390",
      "82adc7cbc5444c0a8ffef89eb6058e9b",
      "f965e091aa424c6e8ff69b7946442eff",
      "b681f2dd85f54a509d75df399fbfc127",
      "e74151d5161c49d7a0d9b4abcc9f6177",
      "26e26f766be64e569558e03ed1ed3079"
     ]
    },
    "id": "5TSK8oXhsSON",
    "outputId": "e4433f0d-331d-4f72-fcf3-db175709edae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbab6e7401e441fa0df143ac971266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c754fbec3dc4838934a9805fa0ac524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a56ff10e48042389c93be00559a51ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64529799d6af434a92a7a874fd4eaeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1ed2a7b6d24443a67c885d911ff3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5fc14894d04b18ac6c13d420d9ad80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is reasoning? The process of forming a conclusion based on evidence, facts, and logical argument. In other words, reasoning is the process of making a decision based on the facts and evidence.\n",
      "How do you know what reasoning is?\n",
      "Reasoning is the process of making a decision based on the facts and evidence. It involves thinking about the problem and coming up with a solution. Reasoning is a key skill in any field, and it can be used to solve problems in many different ways.\n",
      "What is the difference between\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch, os\n",
    "\n",
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"\"\n",
    "\n",
    "model = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"])\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    token=os.environ[\"HUGGINGFACE_HUB_TOKEN\"]\n",
    ")\n",
    "\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "output = llama_pipeline(\"What is reasoning?\", max_new_tokens=100)[0][\"generated_text\"]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRLtx6pqMTUU",
    "outputId": "78e9d157-3433-445f-87f7-3951080c64b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning is the cognitive process of drawing conclusions or making inferences from premises or evidence.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxx-xxx-X-xxx\"\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Give me a one-line definition of 'reasoning'\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBEfAUT7TeyJ",
    "outputId": "113c6748-a2cd-4cdc-f50a-4fb26d330b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reasoning is the process of drawing conclusions or inferences from evidence, facts, or premises using logical principles.\n"
     ]
    }
   ],
   "source": [
    " import os\n",
    " from langchain_anthropic import ChatAnthropic\n",
    "\n",
    " os.environ[\"ANTHROPIC_API_KEY\"] = \"\"\n",
    " llm = ChatAnthropic(\n",
    "     model=\"claude-3-sonnet-20240229\",\n",
    "     temperature=0.2,\n",
    "     max_tokens=1024\n",
    " )\n",
    "\n",
    " response = llm.invoke(\"Explain reasoning in one sentence.\")\n",
    " print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgocqeiuLuyj"
   },
   "source": [
    "#### Delate File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2isGNwYmLuBL"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/ReasoningAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLOlHXNdLzpP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIKR4DRBskbR"
   },
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWJT5W8jw_i_",
    "outputId": "7e51ceb1-a07c-4b4d-d0f2-cb88424620bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Downloading pyngrok-7.2.8-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2GmluM4ZzjvZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vosQLbKU4G-F"
   },
   "source": [
    "### LLM-RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8skrMq94Nq2",
    "outputId": "6e339a45-1d50-43bb-fe90-b899e8a2df4a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'LLM-RGB'...\n",
      "remote: Enumerating objects: 2811, done.\u001B[K\n",
      "remote: Counting objects: 100% (172/172), done.\u001B[K\n",
      "remote: Compressing objects: 100% (69/69), done.\u001B[K\n",
      "remote: Total 2811 (delta 118), reused 103 (delta 103), pack-reused 2639 (from 1)\u001B[K\n",
      "Receiving objects: 100% (2811/2811), 4.16 MiB | 8.02 MiB/s, done.\n",
      "Resolving deltas: 100% (2241/2241), done.\n",
      "/content/ReasoningAI/LLM-RGB\n",
      "\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m rimraf@3.0.2: Rimraf versions prior to v4 are no longer supported\n",
      "\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m har-validator@5.1.5: this library is no longer supported\n",
      "\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142\n",
      "\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m glob@7.2.3: Glob versions prior to v9 are no longer supported\n",
      "\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m uuid@3.4.0: Please upgrade  to version 7 or higher.  Older versions may use Math.random() in certain circumstances, which is known to be problematic.  See https://v8.dev/blog/math-random for details.\n",
      "\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K\u001B[1mnpm\u001B[22m \u001B[33mwarn\u001B[39m \u001B[94mdeprecated\u001B[39m inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.\n",
      "\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K⠼\u001B[1G\u001B[0K⠴\u001B[1G\u001B[0K⠦\u001B[1G\u001B[0K⠧\u001B[1G\u001B[0K⠇\u001B[1G\u001B[0K⠏\u001B[1G\u001B[0K⠋\u001B[1G\u001B[0K⠙\u001B[1G\u001B[0K⠹\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K\n",
      "added 818 packages, and audited 819 packages in 26s\n",
      "\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K\n",
      "\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K100 packages are looking for funding\n",
      "\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K  run `npm fund` for details\n",
      "\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K\n",
      "\u001B[31m\u001B[1m11\u001B[22m\u001B[39m vulnerabilities (7 \u001B[33m\u001B[1mmoderate\u001B[22m\u001B[39m, 3 \u001B[31m\u001B[1mhigh\u001B[22m\u001B[39m, 1 \u001B[35m\u001B[1mcritical\u001B[22m\u001B[39m)\n",
      "\n",
      "To address issues that do not require attention, run:\n",
      "  npm audit fix\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\u001B[1G\u001B[0K⠸\u001B[1G\u001B[0K"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.chdir(\"/content\")\n",
    "!git clone https://github.com/babelcloud/LLM-RGB.git\n",
    "%cd LLM-RGB\n",
    "!npm install\n",
    "!cp promptfooconfig.yaml.example promptfooconfig.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fWRwGmzvgKV",
    "outputId": "263010e3-b10c-4387-d1de-e406aaafefae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tokenizer_config.json: 100% 50.7k/50.7k [00:00<00:00, 15.3MB/s]\n",
      "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 7.22MB/s]\n",
      "special_tokens_map.json: 100% 459/459 [00:00<00:00, 3.65MB/s]\n",
      "/content/ReasoningAI/reflection.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      " * Serving Flask app 'api_server'\n",
      " * Debug mode: off\n",
      "INFO:werkzeug:\u001B[31m\u001B[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001B[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.28.0.12:5000\n",
      "INFO:werkzeug:\u001B[33mPress CTRL+C to quit\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/content/ReasoningAI\")\n",
    "!python api_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzZMJdP1E9th",
    "outputId": "4e5d2443-70de-4dc3-a942-a8ff3c6d1a12"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Your selected num_test_cases = 3\n",
      "\n",
      "Current working directory:\n",
      "  /content/ReasoningAI\n",
      "\n",
      "Test set directory path:\n",
      "  /content/ReasoningAI/LLM-RGB/testcases\n",
      "Directory exists? True\n",
      "\n",
      "Number of YAML files: 15\n",
      "\n",
      "—— File List ——\n",
      " • 005_babel_elements_config.yaml\n",
      " • 002_code_completion_config.yaml\n",
      " • 011_tool_using_config.yaml\n",
      " • 007_simple_vue_config.yaml\n",
      " • 003_context_code_fix_config.yaml\n",
      " • 009_house_color_config.yaml\n",
      " • 001_yaml_format_config.yaml\n",
      " • 012_linux_terminal_config.yaml\n",
      " • 014_find_target_files_config.yaml\n",
      " • 015_simple_mahjong_config.yaml\n",
      " • 004_sed_command_config.yaml\n",
      " • 013_conversation_sanitizer_config.yaml\n",
      " • 008_order_by_points.yaml\n",
      " • 010_daughter_of_time_config.yaml\n",
      " • 006_is_neg_number_config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# —— 1. Manually set the num_test_cases you selected in Streamlit\n",
    "num_test_cases = 3\n",
    "print(f\"Your selected num_test_cases = {num_test_cases}\\n\")\n",
    "\n",
    "# —— 2. Print the current working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"Current working directory:\\n  {cwd}\\n\")\n",
    "\n",
    "# —— 3. Define and check the test case directory\n",
    "testcase_dir = cwd / \"LLM-RGB\" / \"testcases\"\n",
    "print(f\"Test set directory path:\\n  {testcase_dir}\")\n",
    "print(f\"Directory exists? {testcase_dir.exists()}\\n\")\n",
    "\n",
    "# —— 4. If the directory exists, list all .yaml/.yml files and count them\n",
    "if testcase_dir.exists():\n",
    "    yaml_files = list(testcase_dir.glob(\"*.yaml\")) + list(testcase_dir.glob(\"*.yml\"))\n",
    "    print(f\"Number of YAML files: {len(yaml_files)}\\n\")\n",
    "    if yaml_files:\n",
    "        print(\"—— File List ——\")\n",
    "        for f in yaml_files:\n",
    "            print(\" •\", f.name)\n",
    "else:\n",
    "    print(\"⚠️ Directory does not exist, please check if the path is correct.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Z-D7gA_xDNA",
    "outputId": "4c362d84-6ef7-47fe-cb33-a24fd9214be2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Open your app here: NgrokTunnel: \"https://ff16-35-221-187-209.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "from pyngrok import conf, ngrok\n",
    "\n",
    "conf.get_default().auth_token = \"\"\n",
    "public_url = ngrok.connect(8501)\n",
    "print(\"Open your app here:\", public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XrpIpZruTtj",
    "outputId": "0d6ff25e-4d6b-4ddf-eec8-421827d812ef"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001B[0m\n",
      "\u001B[0m\n",
      "\u001B[34m\u001B[1m  You can now view your Streamlit app in your browser.\u001B[0m\n",
      "\u001B[0m\n",
      "\u001B[34m  Local URL: \u001B[0m\u001B[1mhttp://localhost:8501\u001B[0m\n",
      "\u001B[34m  Network URL: \u001B[0m\u001B[1mhttp://172.28.0.12:8501\u001B[0m\n",
      "\u001B[34m  External URL: \u001B[0m\u001B[1mhttp://35.221.187.209:8501\u001B[0m\n",
      "\u001B[0m\n",
      "/content/ReasoningAI/reflection.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      "2025-05-12 20:17:09.362 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo approach this problem, we need to carefully analyze the given information and the calculation that most people quickly make. Let's break it down step by step:\n",
      "\n",
      "1. First, let's examine the given information:\n",
      "   - The exam has two parts\n",
      "   - The student scored 30 out of 100 on Part 1\n",
      "   - The teacher wants the average score of the two parts to be at least 70\n",
      "\n",
      "2. Now, let's look at the quick calculation most people make:\n",
      "   (30 + x) / 2 = 70\n",
      "   x = 110\n",
      "\n",
      "3. Is this the correct way to approach the problem?\n",
      "   The approach is mathematically correct, but it doesn't consider the context of the problem. We need to think about what the result means in terms of exam scores.\n",
      "\n",
      "4. What does the result actually tell us about the situation?\n",
      "   The result of 110 tells us that to achieve an average of 70 with a score of 30 on Part 1, the student would need to score 110 on Part 2. However, this is impossible because exam scores are typically capped at 100.\n",
      "\n",
      "5. What mistake might people make in interpreting the result?\n",
      "   People might mistakenly conclude that it's possible to score 110 on Part 2, or they might think the problem is unsolvable. The real mistake is not recognizing that the result indicates an impossibility within the context of exam scores.\n",
      "\n",
      "6. What deeper insight can we draw about averages and feasibility?\n",
      "   This problem highlights several important insights:\n",
      "   a) Averages can be misleading when we don't consider the constraints of the situation.\n",
      "   b) In real-world scenarios, mathematical solutions must be interpreted within the context of what's actually possible.\n",
      "   c) When dealing with averages, a very low score in one part can make it impossible to achieve a certain overall average, regardless of performance in other parts.\n",
      "   d) It's important to critically evaluate results, especially when they seem unusual or impossible.\n",
      "\n",
      "7. The correct interpretation:\n",
      "   The result actually tells us that it's impossible for the student to achieve an average of 70 given their score of 30 on Part 1. The highest possible average they could achieve would be:\n",
      "   (30 + 100) / 2 = 65\n",
      "\n",
      "This problem serves as a valuable lesson in critical thinking, the importance of context in problem-solving, and the limitations of simple mathematical calculations when applied to real-world scenarios. It also demonstrates how initial low performance can create situations where certain goals become unattainable, regardless of subsequent performance.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: The quick calculation of (30 + x) / 2 = 70, resulting in x = 110, is mathematically correct but not the right way to approach this problem in the context of exam scores. The result actually tells us that it's impossible for the student to achieve an average of 70 given their score of 30 on Part 1. People might mistakenly think it's possible to score 110 on an exam or that the problem is unsolvable. The deeper insight we can draw is that averages can be misleading when we don't consider real-world constraints, and that initial poor performance can create situations where certain goals become unattainable. This problem highlights the importance of critical thinking, considering context in problem-solving, and understanding the limitations of mathematical calculations in practical scenarios.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo approach this problem, we need to carefully analyze the given information and the calculation that most people quickly perform. Let's break down the problem step-by-step and reflect on each aspect.\n",
      "\n",
      "1. Given information:\n",
      "   - Two-part exam\n",
      "   - Student scores 30 out of 100 on Part 1\n",
      "   - Goal: Average score for the two parts to be at least 70\n",
      "\n",
      "2. Common quick calculation:\n",
      "   (30 + x) / 2 = 70\n",
      "   x = 110\n",
      "\n",
      "3. Reflection on the approach:\n",
      "\n",
      "   a) Is this the correct way to approach the problem?\n",
      "      The approach of setting up an equation to find the required score on Part 2 is correct. However, we need to be careful about interpreting the result.\n",
      "\n",
      "   b) What does the result actually tell us about the situation?\n",
      "      The result of x = 110 tells us that to achieve an average of 70 with a score of 30 on Part 1, the student would need to score 110 on Part 2. This is mathematically correct but practically impossible since the maximum score on each part is 100.\n",
      "\n",
      "   c) What mistake might people make in interpreting the result?\n",
      "      People might mistakenly conclude that the student needs to score 110 on Part 2, without realizing that this is impossible on a 100-point scale. They might not question the feasibility of the result.\n",
      "\n",
      "   d) What deeper insight can we draw about averages and feasibility?\n",
      "      This problem highlights several important insights:\n",
      "      - Averages can be misleading when dealing with constrained values.\n",
      "      - It's crucial to consider the practical limitations of a problem, not just the mathematical solution.\n",
      "      - A mathematically correct solution may not always be practically achievable.\n",
      "      - When one value in an average is very low, it may be impossible to reach a target average within the given constraints.\n",
      "\n",
      "4. Correct interpretation:\n",
      "   The correct conclusion is that it's impossible for the student to achieve an average of 70 given their score of 30 on Part 1. Even if they score a perfect 100 on Part 2, their average would be:\n",
      "   (30 + 100) / 2 = 65\n",
      "\n",
      "5. Maximum possible average:\n",
      "   The highest average the student can achieve is 65, which occurs when they score 100 on Part 2.\n",
      "\n",
      "6. Lesson learned:\n",
      "   This problem teaches us to always check our mathematical results against the practical constraints of the real-world situation. It also demonstrates how a very low score in one part can make it impossible to achieve a target average, no matter how well one performs in the other part.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: The common quick calculation of (30 + x) / 2 = 70, resulting in x = 110, is mathematically correct but practically impossible. This approach reveals several important insights:\n",
      "\n",
      "1. The result actually tells us that it's impossible for the student to achieve an average of 70 given their score of 30 on Part 1.\n",
      "\n",
      "2. People might mistakenly think the student needs to score 110 on Part 2, without realizing this is impossible on a 100-point scale.\n",
      "\n",
      "3. The deeper insights we can draw are:\n",
      "   a) Averages can be misleading when dealing with constrained values.\n",
      "   b) It's crucial to consider practical limitations, not just mathematical solutions.\n",
      "   c) A mathematically correct solution may not always be practically achievable.\n",
      "   d) When one value in an average is very low, it may be impossible to reach a target average within given constraints.\n",
      "\n",
      "4. The maximum average the student can achieve is 65, by scoring 100 on Part 2.\n",
      "\n",
      "This problem teaches us to always check our mathematical results against real-world constraints and demonstrates how a very low score in one part can make it impossible to achieve a target average, regardless of performance in the other part.\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/langchain/memory/chat_memory.py:55: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'intermediate_steps']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  warnings.warn(\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "2025-05-12 20:59:13.060 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "Randomly sampled 3 test cases.\n",
      "Loaded 3 test cases from LLM-RGB.\n",
      "Evaluating on 3 samples...\n",
      "  0% 0/3 [00:00<?, ?it/s]\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo address this requirement, I'll need to create a photo management system with album creation functionality. I'll break this down into several components and create the necessary Babel elements. Let's start with the dependencies and then move on to the elements.\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"best practices for photo management web applications\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'best practices for photo management web applications\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Best practices for cloud photo management - Box Blog', 'url': 'https://blog.box.com/best-practices-for-cloud-photo-management', 'content': \"How to manage digital photos in the cloud: 7 best practices Whether you're using photos in your marketing materials, training documentation, customer testimonials, or other business applications, you need efficient photo management. Here are the seven best practices for digital photo management. 1. Choose a secure cloud platform\", 'score': 0.8018276, 'raw_content': None}, {'title': '5 Best Practices Of Image Management - ImageKit.io', 'url': 'https://imagekit.io/blog/5-best-practices-image-management/', 'content': 'Optimize Your Website Images You can use various plugins to optimize your website images, or you can go for real-time image optimization. The best image management practice to handle the loading of broken images is using a third party image server such as ImageKit. It saves you from building your own server, a very costly and time consuming process. ImageKit uses URL-based transformations and provides server-side handling to prevent loading of non-existent images. Using progressive JPEG on your websites improves the user experience by loading the full image faster as compared to the top-down loading method. ImageKit provides all image management solutions on the go and helps you in simplifying your workflow and improving your website experience. More in Image Optimization', 'score': 0.69199765, 'raw_content': None}, {'title': 'A Guide to Image Management - Acquia', 'url': 'https://www.acquia.com/blog/image-management', 'content': 'Best practices for managing images. Purchasing and installing image management software can be a significant investment of both time and money. Here are some best practices to help maximize its value. Have a dedicated system administrator: Managing content currency and user access to an image collection is an ongoing job.', 'score': 0.6213807, 'raw_content': None}, {'title': 'Photo Management Guide for Amateurs and Pros | Smartsheet', 'url': 'https://www.smartsheet.com/photo-management-software-guide', 'content': 'Photo Management Best Practices and Resources; ... the web sharing can be linked to the same software that you are using to organize and optimize your photos.\" ... too. Your smartphone comes with its stock photo management apps with great features, but they may not tick every box. You may want to look at alternative photo managers for Android', 'score': 0.57780564, 'raw_content': None}, {'title': '11 Best Photo Management Software in 2025 (Updated) - ExpertPhotography', 'url': 'https://expertphotography.com/best-photo-management-software/', 'content': 'Revolutionary AI tools for photo managing and editing Includes AI-powered tools for editing and organizing photos This photo management software is not for those who want built-in editing tools. ACDSee Photo Studio Ultimate has AI-enhanced image management and Photoshop-style editing. So it’s the best photo management software for Windows users who want powerful, built-in editing. BrandBrandLuminarOperating SystemOperating SystemmacOS and WindowsPayment TypePayment Type12-month subscription / One-time paymentFree Trial PeriodFree Trial Period30-day money-back guaranteeKey FeaturesKey FeaturesAI enhancement and editing tools, powerline removal AI, sky replacement AI, layers, filtersBest ForBest ForMac and Windows users, photographers of all levels, social media content creators Adobe Lightroom is the best photo management software, thanks to its great features and brilliant editing tools.', 'score': 0.507251, 'raw_content': None}, {'title': 'Managing Photo: Techniques and Best Practices', 'url': 'https://scifusions.com/articles/managing-photo-techniques-best-practices/', 'content': 'Effective photo management does not rely solely on theoretical knowledge; it is enriched by real-world examples. This section delves into case studies that illustrate successful photo management practices. These case studies not only showcase individual approaches but also emphasize the diverse strategies employed by different types of', 'score': 0.49758363, 'raw_content': None}, {'title': 'What Is Image Management - Pics.io', 'url': 'https://blog.pics.io/practical-guide-on-image-management/', 'content': 'Learn about the importance of image management, key benefits, and best practices for organizing and distributing digital assets. Featured posts; ... Modern image management software has integrations with many applications and web services. These include content management systems (CMS), customer relationship management (CRM) platforms, graphic', 'score': 0.43539792, 'raw_content': None}, {'title': 'Best Photo Management Software Reviews 2025 - Gartner', 'url': 'https://www.gartner.com/reviews/market/photo-management-software', 'content': 'ACD Systems, founded in 1993 by Doug Vandekerkhove, is an independent digital image editing and management company based in Texas. The company realized the prospect of analog and digital convergence, thus contributing to advancement in the use of analog and digital data in various pre-web applications. ACD Systems owns seven patents, with its', 'score': 0.37339646, 'raw_content': None}, {'title': 'Image Management Systems: Key Capabilities and Best Practices', 'url': 'https://cloudinary.com/guides/web-performance/image-management-systems-key-capabilities-and-best-practices', 'content': 'While image management systems primarily focus on handling digital images, DAM solutions offer comprehensive features to manage various media types, ensuring seamless integration, collaboration, and distribution across multiple channels and platforms. Cloudinary’s Media Library makes it easy to upload, store, manage, and deliver images and videos efficiently. DAM software is a comprehensive solution designed to manage not just images but a vast array of digital assets including videos, design files, 3D files, and documents.', 'score': 0.3460776, 'raw_content': None}, {'title': 'Guide to Digital Image Management - Cloudinary', 'url': 'https://cloudinary.com/guides/digital-asset-management/guide-to-digital-image-management', 'content': \"Top 10 Benefits of Digital Asset Management for Marketing; Digital Asset Management for Small Businesses: The Ultimate Beginner's Guide; Five Best DAM Software for Photographers; 5 Reasons Why Digital Asset Management for Advertising Agencies is Essential; The Ultimate Guide to Digital Asset Management for Designers\", 'score': 0.11300102, 'raw_content': None}], 'response_time': 1.78}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results and best practices for photo management web applications, I'll create a Babel application that includes the necessary elements for managing photos, creating albums, and sharing them. Let's start with the dependencies and then move on to the elements.\n",
      "\n",
      "dependencies:\n",
      "  ejs: 3.1.9\n",
      "  multer: 1.4.5-lts.1\n",
      "  sharp: 0.32.1\n",
      "  uuid: 9.0.0\n",
      "\n",
      "elements:\n",
      "- name: Photo\n",
      "  kind: Database\n",
      "  code: |+\n",
      "    /**\n",
      "     * This element defines the photo structure to save in your photo management system.\n",
      "     **/\n",
      "    export type PhotoRecord = {\n",
      "        id: string; // Unique identifier for the photo\n",
      "        filename: string; // Original filename of the photo\n",
      "        path: string; // Path where the photo is stored\n",
      "        thumbnailPath: string; // Path to the thumbnail of the photo\n",
      "        uploadDate: Date; // Date when the photo was uploaded\n",
      "        albumIds: string[]; // IDs of albums this photo belongs to\n",
      "    }\n",
      "\n",
      "- name: Album\n",
      "  kind: Database\n",
      "  code: |+\n",
      "    /**\n",
      "     * This element defines the album structure to save in your photo management system.\n",
      "     **/\n",
      "    export type AlbumRecord = {\n",
      "        id: string; // Unique identifier for the album\n",
      "        name: string; // Name of the album\n",
      "        description: string; // Description of the album\n",
      "        creationDate: Date; // Date when the album was created\n",
      "        photoIds: string[]; // IDs of photos in this album\n",
      "        shareLink: string; // Unique link for sharing the album\n",
      "    }\n",
      "\n",
      "- name: PhotoStore\n",
      "  kind: Storage\n",
      "  maxFileSize: 20MB\n",
      "  allowContentTypes:\n",
      "  - image/*\n",
      "\n",
      "- name: UploadPhoto\n",
      "  kind: HTTP\n",
      "  method: POST\n",
      "  pathname: /upload\n",
      "  code: |+\n",
      "    import multer from 'multer';\n",
      "    import sharp from 'sharp';\n",
      "    import { v4 as uuidv4 } from 'uuid';\n",
      "    import { Photo, PhotoStore } from '#elements';\n",
      "    import * as Koa from \"koa\";\n",
      "\n",
      "    const upload = multer({ storage: multer.memoryStorage() });\n",
      "\n",
      "    /**\n",
      "     * API endpoint to handle photo upload\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        upload.single('photo')(ctx, async () => {\n",
      "            const file = ctx.file;\n",
      "            const id = uuidv4();\n",
      "            const filename = file.originalname;\n",
      "            const path = `photos/${id}-${filename}`;\n",
      "            const thumbnailPath = `thumbnails/${id}-${filename}`;\n",
      "\n",
      "            // Save original photo\n",
      "            await PhotoStore.put(path, file.buffer);\n",
      "\n",
      "            // Generate and save thumbnail\n",
      "            const thumbnail = await sharp(file.buffer)\n",
      "                .resize(200, 200, { fit: 'inside' })\n",
      "                .toBuffer();\n",
      "            await PhotoStore.put(thumbnailPath, thumbnail);\n",
      "\n",
      "            // Save photo record to database\n",
      "            const photoRecord: PhotoRecord = {\n",
      "                id,\n",
      "                filename,\n",
      "                path,\n",
      "                thumbnailPath,\n",
      "                uploadDate: new Date(),\n",
      "                albumIds: []\n",
      "            };\n",
      "            await Photo.set(id, photoRecord);\n",
      "\n",
      "            return { message: 'Photo uploaded successfully', id };\n",
      "        });\n",
      "    }\n",
      "\n",
      "- name: DeletePhoto\n",
      "  kind: HTTP\n",
      "  method: DELETE\n",
      "  pathname: /photos/:id\n",
      "  code: |+\n",
      "    import { Photo, PhotoStore, Album } from '#elements';\n",
      "    import * as Koa from \"koa\";\n",
      "\n",
      "    /**\n",
      "     * API endpoint to delete a photo\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { id } = request.params;\n",
      "        const photo = await Photo.get(id);\n",
      "\n",
      "        if (!photo) {\n",
      "            return { error: 'Photo not found' };\n",
      "        }\n",
      "\n",
      "        // Remove photo from albums\n",
      "        for (const albumId of photo.albumIds) {\n",
      "            const album = await Album.get(albumId);\n",
      "            album.photoIds = album.photoIds.filter(photoId => photoId !== id);\n",
      "            await Album.set(albumId, album);\n",
      "        \u001B[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001B[32;1m\u001B[1;3mI apologize for the formatting error. Let me continue with the proper format:\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"best practices for creating and sharing photo albums in web applications\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'best practices for creating and sharing photo albums in web applications\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'How to Share Photos & Galleries with Clients - Picflow', 'url': 'https://picflow.com/blog/best-way-to-share-photos-with-clients', 'content': 'Best Practices for Sharing Photos With Clients 1. Opt for a Secure Photo-Sharing Platform. Select a trustworthy platform or service for sharing photographs. This could range from a client-specific gallery on your website to a specialized photo-sharing platform, or even a secure cloud storage service featuring password protection.', 'score': 0.71377134, 'raw_content': None}, {'title': 'Best Practices for Uploading Photos to Online Albums', 'url': 'https://fotoplayer.com/best-practices-for-uploading-photos-to-online-albums/', 'content': \"Uploading full-resolution images straight from a camera or phone can slow down album performance. Most platforms automatically resize images, but it's best to optimize them beforehand. For web albums: 1600px on the longest side is a good balance between quality and speed. For printing: Keep the full resolution to ensure sharpness.\", 'score': 0.6659544, 'raw_content': None}, {'title': 'Top Guide on Online Photo Album Sharing - fonetool.com', 'url': 'https://www.fonetool.com/explore/online-photo-album-sharing-0612-ac.html', 'content': 'Whether you want to showcase your latest vacation, celebrate special occasions, or simply share everyday moments, there are various platforms designed to make online photo album sharing a seamless experience. In this comprehensive guide, we will explore the best practices, platforms, and tips for creating and sharing stunning photo albums', 'score': 0.60750073, 'raw_content': None}, {'title': 'Managing Photo: Techniques and Best Practices', 'url': 'https://scifusions.com/articles/managing-photo-techniques-best-practices/', 'content': 'This makes external SSDs a beneficial choice for photographers who require quick access to their images and editing tools, especially during events or photo shoots. Creating a photo display is an important aspect of managing digital images. One unique feature of photo sharing websites is the built-in tools for organizing images into albums or categories, making it easier both for photographers to manage their portfolios and for viewers to navigate through the content. Utilization of Cloud Services: With a plethora of easy-to-use cloud storage options available like Google Photos and Dropbox, amateur photographers can back up their images without needing extensive knowledge of digital tools. As digital photography continues to evolve, understanding how to manage photos effectively enhances workflow and accessibility.', 'score': 0.5976789, 'raw_content': None}, {'title': 'Top best photo sharing websites to use in 2025 - MacPaw', 'url': 'https://macpaw.com/how-to/photo-sharing-websites', 'content': \"Cluster: The best app for collaborative photo sharing. Out of our list here, Cluster is the best photo sharing app when it comes to collaborative sharing. As soon as you log into Cluster for the first time, you're prompted to create an album around a specific event or theme.\", 'score': 0.568632, 'raw_content': None}, {'title': 'Create and share an online album - Adobe Inc.', 'url': 'https://helpx.adobe.com/elements-organizer/using/create-share-online-album.html', 'content': 'Online albums come in various traditional layouts and designs, and are optimized for viewing images on a web page. The Online Album wizard guides you through the process of adding and arranging media files, applying layout templates, and sharing the files.', 'score': 0.49978086, 'raw_content': None}, {'title': 'Best Way To Share Photos For Work And Personal Purposes - Skylum', 'url': 'https://skylum.com/blog/best-way-to-share-photos', 'content': 'Share With Care: Sharing a photo or an album with a link is super easy, but be careful. If the wrong person gets the link, they can see your photographs. ... Create a System: Sorting your images is similar to organizing a personal library. Whether you arrange them by date, event, or people, the goal is to make finding a specific photo as', 'score': 0.45754927, 'raw_content': None}, {'title': 'How to Put a Photo Album on a Web Page | HowStuffWorks', 'url': 'https://computer.howstuffworks.com/internet/basics/how-to-put-a-photo-album-on-a-web-page.htm', 'content': 'A digital photo album is a collection of pictures, which you can organize on your Web site. A Web album makes it easy for you to organize and edit your digital photos. You can then share your album with friends and family [source: Picasa]. Many online photo developing sites offer the option of setting up a photo album.', 'score': 0.41520765, 'raw_content': None}, {'title': 'Easy Guide: How To Make A Secured Shared Album Online - Showell', 'url': 'https://www.showell.com/the-hub/how-to-make-a-secured-shared-album', 'content': 'If you are an Apple user, you can use iCloud Photos to create shared albums. You can create an album, invite others to join, and then add photos and videos to it. Members can also add photos and videos, and you can set different access levels for each member. 3. Dropbox. Dropbox offers a feature called \"Shared Folders\" that allows you to create', 'score': 0.34634283, 'raw_content': None}, {'title': '5 Free Online Photo Album Creators to Share Pictures and Photo ... - MUO', 'url': 'https://www.makeuseof.com/free-online-photo-album-creators-share-pictures-photo-essays/', 'content': 'These free online photo album creators offer unique ways to show your images to anyone, with captions too.', 'score': 0.27365613, 'raw_content': None}], 'response_time': 1.87}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results and best practices for creating and sharing photo albums in web applications, I'll continue building our Babel application with elements for managing albums, creating shareable links, and viewing photos. Let's add the necessary elements:\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"best practices for secure photo sharing and album creation in web applications\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'best practices for secure photo sharing and album creation in web applications\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Best Practices for Secure File Uploads in Web Apps', 'url': 'https://techarry.com/best-practices-for-secure-file-uploads-in-web-apps/', 'content': 'Discover best practices for secure file uploads in web apps, including file validation, storage, and malware scanning to protect your system. ... In modern web applications, file uploads are a fundamental feature, enabling users to share data such as images, documents, and videos. ... if you are building a photo-sharing application, restrict', 'score': 0.7746691, 'raw_content': None}, {'title': 'How to Share Photos & Galleries with Clients - Picflow', 'url': 'https://picflow.com/blog/best-way-to-share-photos-with-clients', 'content': 'Best Practices for Sharing Photos With Clients 1. Opt for a Secure Photo-Sharing Platform. Select a trustworthy platform or service for sharing photographs. This could range from a client-specific gallery on your website to a specialized photo-sharing platform, or even a secure cloud storage service featuring password protection.', 'score': 0.73891455, 'raw_content': None}, {'title': 'Best Secure Photo Sharing Options: Keep Your Memories Safe Online', 'url': 'https://howtogetorganizedathome.com/secure-photo-sharing/', 'content': \"Best Secure Photo Sharing Services: Pros And Cons. Choosing the right photo-sharing platform depends on your needs. If you're looking for a simple way to share family photos, a basic cloud storage service with private albums may be enough.But if security is your top priority, opt for a platform with encryption and password-protected sharing.. Here's a quick comparison of the best secure\", 'score': 0.6083387, 'raw_content': None}, {'title': 'Data-Protected Cloud-Based Photo Album Sharing - HIVO', 'url': 'https://hivo.co/blog/secure-cloud-based-photo-album-sharing-data-protection-for-collaborators', 'content': \"1. Introduction to Cloud-Based Photo Album Sharing. Before we delve into the importance of data protection in cloud-based photo album sharing, let's first understand the concept of cloud storage. Cloud storage refers to the practice of storing digital data on remote servers accessed through the internet.\", 'score': 0.36269882, 'raw_content': None}, {'title': '10+ Ways To Protect Your Photos From Leaks - Dulab Innovations', 'url': 'https://dulab.phys.rice.edu/10-ways-to-protect-your-photos-from-leaks', 'content': 'Limit Sharing and Use Secure Transfer Methods. Be cautious about who you share your photos with. When sharing is necessary, use secure methods such as encrypted email services or messaging apps that offer end-to-end encryption, like Signal. Avoid sharing sensitive photos on social media or through unsecured channels. 6. Store Photos Securely', 'score': 0.3579046, 'raw_content': None}, {'title': 'Security Checklist for Web Application | SANS Institute', 'url': 'https://www.sans.org/cloud-security/securing-web-application-technologies/', 'content': 'All components of infrastructure that support the application should be configured according to security best practices and hardening guidelines. In a typical web application this can include routers, firewalls, network switches, operating systems, web servers, application servers, databases, and application frameworks.', 'score': 0.30358776, 'raw_content': None}, {'title': '4 ways to share photos online privately - Proton', 'url': 'https://proton.me/blog/share-photos-online-privately', 'content': \"3. Secure email. Sharing photos via email has some significant drawbacks, but it's worth including email on this list because it's so common. The biggest obstacle to sharing photos over email is the file size limit. Most email platforms cap attachments at 25 MB. Certainly if you're trying to send whole folders, email is not the way to go.\", 'score': 0.25160676, 'raw_content': None}, {'title': 'Tips To Safely Share Photos Online - Security Boulevard', 'url': 'https://securityboulevard.com/2024/03/tips-to-safely-share-photos-online/', 'content': 'Application Security\\xa0Cloud Security\\xa0Cyberlaw\\xa0Cybersecurity\\xa0Data Privacy\\xa0Data Security\\xa0DevOps\\xa0Featured\\xa0Governance, Risk & Compliance\\xa0Humor\\xa0Identity & Access\\xa0Incident Response\\xa0Industry Spotlight\\xa0IoT & ICS Security\\xa0Malware\\xa0Mobile Security\\xa0Most Read This Week\\xa0Network Security\\xa0News\\xa0Popular Post\\xa0Security Awareness\\xa0Security Boulevard (Original)\\xa0Social - Facebook\\xa0Social - LinkedIn\\xa0Social - X\\xa0Spotlight\\xa0Threats & Breaches\\xa0Vulnerabilities\\xa0 Analytics & Intelligence\\xa0Cloud Security\\xa0Cyberlaw\\xa0Cybersecurity\\xa0Data Privacy\\xa0DevOps\\xa0Featured\\xa0Governance, Risk & Compliance\\xa0Humor\\xa0Industry Spotlight\\xa0Most Read This Week\\xa0News\\xa0Popular Post\\xa0Security Awareness\\xa0Security Boulevard (Original)\\xa0Social - Facebook\\xa0Social - LinkedIn\\xa0Social - X\\xa0Spotlight\\xa0Threat Intelligence\\xa0Threats & Breaches\\xa0', 'score': 0.21708052, 'raw_content': None}, {'title': 'The Best Online Photo Storage Services for 2025 - PCMag', 'url': 'https://www.pcmag.com/picks/best-online-photo-storage-services', 'content': 'The Best Online Photo Storage Services for 2025 | PCMag The Best Online Photo Storage Services for 2025 Use one of the best online photo storage services to keep them all together, accessible from anywhere, and easy to share. The best online photo storage services give you a place to consolidate and organize all the images from your phone and camera. Best Photo Editing Apps Best Mobile Apps for Editing Photos Like most of the best online photo storage services, SmugMug has mobile and desktop apps, as well as plug-ins that work with Adobe Lightroom Classic and Capture One. You can even do limited editing: applying a few color and B&W effects, cropping, and rotating. The Best Mobile Photo Editing Apps for 2025', 'score': 0.16202202, 'raw_content': None}, {'title': \"The best photo storage and sharing sites in 2025 | Tom's Guide\", 'url': 'https://www.tomsguide.com/best-picks/best-photography-sites', 'content': \"(Image credit: Google) Jump to: Best photo storage sites Best general cloud services How to choose How best to store photos How much storage How we test The best photo storage sites are vital if you take a lot of photos. The best photo storage sites will give you the space you need to store your images, and should give you the option to expand your storage later on if you need to. They'll also give you the reassurance that your image library is backed up to the cloud, so you won't lose everything should your hard drive go kaput. Since being sold to SmugMug, the company announced a cap of 1,000 photos on free accounts.\", 'score': 0.14541878, 'raw_content': None}], 'response_time': 2.17}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results and best practices for secure photo sharing and album creation in web applications, I'll continue building our Babel application with elements for managing albums, creating shareable links, and viewing photos. Let's add the necessary elements:\n",
      "\n",
      "dependencies:\n",
      "  ejs: 3.1.9\n",
      "  multer: 1.4.5-lts.1\n",
      "  sharp: 0.32.1\n",
      "  uuid: 9.0.0\n",
      "  bcrypt: 5.1.0\n",
      "\n",
      "elements:\n",
      "- name: CreateAlbum\n",
      "  kind: HTTP\n",
      "  method: POST\n",
      "  pathname: /albums\n",
      "  code: |+\n",
      "    import { v4 as uuidv4 } from 'uuid';\n",
      "    import { Album } from '#elements';\n",
      "    import * as Koa from \"koa\";\n",
      "\n",
      "    /**\n",
      "     * API endpoint to create a new album\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { name, description } = request.body;\n",
      "        const id = uuidv4();\n",
      "        const shareLink = uuidv4(); // Generate a unique share link\n",
      "\n",
      "        const albumRecord: AlbumRecord = {\n",
      "            id,\n",
      "            name,\n",
      "            description,\n",
      "            creationDate: new Date(),\n",
      "            photoIds: [],\n",
      "            shareLink\n",
      "        };\n",
      "\n",
      "        await Album.set(id, albumRecord);\n",
      "        return { message: 'Album created successfully', id, shareLink };\n",
      "    }\n",
      "\n",
      "- name: AddPhotoToAlbum\n",
      "  kind: HTTP\n",
      "  method: POST\n",
      "  pathname: /albums/:albumId/photos/:photoId\n",
      "  code: |+\n",
      "    import { Album, Photo } from '#elements';\n",
      "    import * as Koa from \"koa\";\n",
      "\n",
      "    /**\n",
      "     * API endpoint to add a photo to an album\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { albumId, photoId } = request.params;\n",
      "\n",
      "        const album = await Album.get(albumId);\n",
      "        const photo = await Photo.get(photoId);\n",
      "\n",
      "        if (!album || !photo) {\n",
      "            return { error: 'Album or photo not found' };\n",
      "        }\n",
      "\n",
      "        if (!album.photoIds.includes(photoId)) {\n",
      "            album.photoIds.push(photoId);\n",
      "            await Album.set(albumId, album);\n",
      "        }\n",
      "\n",
      "        if (!photo.albumIds.includes(albumId)) {\n",
      "            photo.albumIds.push(albumId);\n",
      "            await Photo.set(photoId, photo);\n",
      "        }\n",
      "\n",
      "        return { message: 'Photo added to album successfully' };\n",
      "    }\n",
      "\n",
      "- name: ViewAlbum\n",
      "  kind: HTTP\n",
      "  method: GET\n",
      "  pathname: /albums/:id\n",
      "  code: |+\n",
      "    import { Album, Photo } from '#elements';\n",
      "    import { frontend } from \"#elements\";\n",
      "    import * as Koa from \"koa\";\n",
      "    import * as ejs from \"ejs\";\n",
      "\n",
      "    /**\n",
      "     * Renders album.ejs, displaying all photos in the album\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { id } = request.params;\n",
      "        const album = await Album.get(id);\n",
      "\n",
      "        if (!album) {\n",
      "            return { error: 'Album not found' };\n",
      "        }\n",
      "\n",
      "        const photos = await Promise.all(album.photoIds.map(photoId => Photo.get(photoId)));\n",
      "        const html = ejs.render(await frontend[\"/album.ejs\"].text(), { album, photos });\n",
      "        return html;\n",
      "    }\n",
      "\n",
      "- name: ShareAlbum\n",
      "  kind: HTTP\n",
      "  method: GET\n",
      "  pathname: /share/:shareLink\n",
      "  code: |+\n",
      "    import { Album, Photo } from '#elements';\n",
      "    import { frontend } from \"#elements\";\n",
      "    import * as Koa from \"koa\";\n",
      "    import * as ejs from \"ejs\";\n",
      "\n",
      "    /**\n",
      "     * Renders shared-album.ejs, displaying all photos in the shared album\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { share\u001B[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001B[32;1m\u001B[1;3mI apologize for the formatting error. Let me continue with the proper format:\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"best practices for secure photo sharing and album creation in web applications\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'best practices for secure photo sharing and album creation in web applications\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Best Practices for Secure File Uploads in Web Apps', 'url': 'https://techarry.com/best-practices-for-secure-file-uploads-in-web-apps/', 'content': 'Discover best practices for secure file uploads in web apps, including file validation, storage, and malware scanning to protect your system. ... In modern web applications, file uploads are a fundamental feature, enabling users to share data such as images, documents, and videos. ... if you are building a photo-sharing application, restrict', 'score': 0.7746691, 'raw_content': None}, {'title': 'How to Share Photos & Galleries with Clients - Picflow', 'url': 'https://picflow.com/blog/best-way-to-share-photos-with-clients', 'content': 'Best Practices for Sharing Photos With Clients 1. Opt for a Secure Photo-Sharing Platform. Select a trustworthy platform or service for sharing photographs. This could range from a client-specific gallery on your website to a specialized photo-sharing platform, or even a secure cloud storage service featuring password protection.', 'score': 0.73891455, 'raw_content': None}, {'title': 'Best Secure Photo Sharing Options: Keep Your Memories Safe Online', 'url': 'https://howtogetorganizedathome.com/secure-photo-sharing/', 'content': \"Best Secure Photo Sharing Services: Pros And Cons. Choosing the right photo-sharing platform depends on your needs. If you're looking for a simple way to share family photos, a basic cloud storage service with private albums may be enough.But if security is your top priority, opt for a platform with encryption and password-protected sharing.. Here's a quick comparison of the best secure\", 'score': 0.6083387, 'raw_content': None}, {'title': 'Data-Protected Cloud-Based Photo Album Sharing - HIVO', 'url': 'https://hivo.co/blog/secure-cloud-based-photo-album-sharing-data-protection-for-collaborators', 'content': \"1. Introduction to Cloud-Based Photo Album Sharing. Before we delve into the importance of data protection in cloud-based photo album sharing, let's first understand the concept of cloud storage. Cloud storage refers to the practice of storing digital data on remote servers accessed through the internet.\", 'score': 0.36269882, 'raw_content': None}, {'title': '10+ Ways To Protect Your Photos From Leaks - Dulab Innovations', 'url': 'https://dulab.phys.rice.edu/10-ways-to-protect-your-photos-from-leaks', 'content': 'Limit Sharing and Use Secure Transfer Methods. Be cautious about who you share your photos with. When sharing is necessary, use secure methods such as encrypted email services or messaging apps that offer end-to-end encryption, like Signal. Avoid sharing sensitive photos on social media or through unsecured channels. 6. Store Photos Securely', 'score': 0.3579046, 'raw_content': None}, {'title': 'Security Checklist for Web Application | SANS Institute', 'url': 'https://www.sans.org/cloud-security/securing-web-application-technologies/', 'content': 'All components of infrastructure that support the application should be configured according to security best practices and hardening guidelines. In a typical web application this can include routers, firewalls, network switches, operating systems, web servers, application servers, databases, and application frameworks.', 'score': 0.30358776, 'raw_content': None}, {'title': '4 ways to share photos online privately - Proton', 'url': 'https://proton.me/blog/share-photos-online-privately', 'content': \"3. Secure email. Sharing photos via email has some significant drawbacks, but it's worth including email on this list because it's so common. The biggest obstacle to sharing photos over email is the file size limit. Most email platforms cap attachments at 25 MB. Certainly if you're trying to send whole folders, email is not the way to go.\", 'score': 0.25160676, 'raw_content': None}, {'title': 'Tips To Safely Share Photos Online - Security Boulevard', 'url': 'https://securityboulevard.com/2024/03/tips-to-safely-share-photos-online/', 'content': 'Application Security\\xa0Cloud Security\\xa0Cyberlaw\\xa0Cybersecurity\\xa0Data Privacy\\xa0Data Security\\xa0DevOps\\xa0Featured\\xa0Governance, Risk & Compliance\\xa0Humor\\xa0Identity & Access\\xa0Incident Response\\xa0Industry Spotlight\\xa0IoT & ICS Security\\xa0Malware\\xa0Mobile Security\\xa0Most Read This Week\\xa0Network Security\\xa0News\\xa0Popular Post\\xa0Security Awareness\\xa0Security Boulevard (Original)\\xa0Social - Facebook\\xa0Social - LinkedIn\\xa0Social - X\\xa0Spotlight\\xa0Threats & Breaches\\xa0Vulnerabilities\\xa0 Analytics & Intelligence\\xa0Cloud Security\\xa0Cyberlaw\\xa0Cybersecurity\\xa0Data Privacy\\xa0DevOps\\xa0Featured\\xa0Governance, Risk & Compliance\\xa0Humor\\xa0Industry Spotlight\\xa0Most Read This Week\\xa0News\\xa0Popular Post\\xa0Security Awareness\\xa0Security Boulevard (Original)\\xa0Social - Facebook\\xa0Social - LinkedIn\\xa0Social - X\\xa0Spotlight\\xa0Threat Intelligence\\xa0Threats & Breaches\\xa0', 'score': 0.21708052, 'raw_content': None}, {'title': 'The Best Online Photo Storage Services for 2025 - PCMag', 'url': 'https://www.pcmag.com/picks/best-online-photo-storage-services', 'content': 'The Best Online Photo Storage Services for 2025 | PCMag The Best Online Photo Storage Services for 2025 Use one of the best online photo storage services to keep them all together, accessible from anywhere, and easy to share. The best online photo storage services give you a place to consolidate and organize all the images from your phone and camera. Best Photo Editing Apps Best Mobile Apps for Editing Photos Like most of the best online photo storage services, SmugMug has mobile and desktop apps, as well as plug-ins that work with Adobe Lightroom Classic and Capture One. You can even do limited editing: applying a few color and B&W effects, cropping, and rotating. The Best Mobile Photo Editing Apps for 2025', 'score': 0.16202202, 'raw_content': None}, {'title': \"The best photo storage and sharing sites in 2025 | Tom's Guide\", 'url': 'https://www.tomsguide.com/best-picks/best-photography-sites', 'content': \"(Image credit: Google) Jump to: Best photo storage sites Best general cloud services How to choose How best to store photos How much storage How we test The best photo storage sites are vital if you take a lot of photos. The best photo storage sites will give you the space you need to store your images, and should give you the option to expand your storage later on if you need to. They'll also give you the reassurance that your image library is backed up to the cloud, so you won't lose everything should your hard drive go kaput. Since being sold to SmugMug, the company announced a cap of 1,000 photos on free accounts.\", 'score': 0.14541878, 'raw_content': None}], 'response_time': 1.2}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results and best practices for secure photo sharing and album creation in web applications, I'll continue building our Babel application with elements for managing albums, creating shareable links, and viewing photos. Let's add the necessary elements:\n",
      "\n",
      "dependencies:\n",
      "  ejs: 3.1.9\n",
      "  multer: 1.4.5-lts.1\n",
      "  sharp: 0.32.1\n",
      "  uuid: 9.0.0\n",
      "  bcrypt: 5.1.0\n",
      "\n",
      "elements:\n",
      "- name: ShareAlbum\n",
      "  kind: HTTP\n",
      "  method: GET\n",
      "  pathname: /share/:shareLink\n",
      "  code: |+\n",
      "    import { Album, Photo } from '#elements';\n",
      "    import { frontend } from \"#elements\";\n",
      "    import * as Koa from \"koa\";\n",
      "    import * as ejs from \"ejs\";\n",
      "\n",
      "    /**\n",
      "     * Renders shared-album.ejs, displaying all photos in the shared album\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const { shareLink } = request.params;\n",
      "        const albums = await Album.query({ shareLink });\n",
      "\n",
      "        if (albums.length === 0) {\n",
      "            return { error: 'Album not found' };\n",
      "        }\n",
      "\n",
      "        const album = albums[0];\n",
      "        const photos = await Promise.all(album.photoIds.map(photoId => Photo.get(photoId)));\n",
      "        const html = ejs.render(await frontend[\"/shared-album.ejs\"].text(), { album, photos });\n",
      "        return html;\n",
      "    }\n",
      "\n",
      "- name: ManagePhotos\n",
      "  kind: HTTP\n",
      "  method: GET\n",
      "  pathname: /manage\n",
      "  code: |+\n",
      "    import { Photo, Album } from '#elements';\n",
      "    import { frontend } from \"#elements\";\n",
      "    import * as Koa from \"koa\";\n",
      "    import * as ejs from \"ejs\";\n",
      "\n",
      "    /**\n",
      "     * Renders manage.ejs, displaying all photos and albums for management\n",
      "     **/\n",
      "    export default async function(request: Koa.Request, response: Koa.Response, ctx: Koa.Context) {\n",
      "        const photos = await Photo.list();\n",
      "        const albums = await Album.list();\n",
      "        const html = ejs.render(await frontend[\"/manage.ejs\"].text(), { photos, albums });\n",
      "        return html;\n",
      "    }\n",
      "\n",
      "- name: frontend\n",
      "  kind: Assets\n",
      "  items:\n",
      "  - path: /manage.ejs\n",
      "    type: text/plain\n",
      "    content: |\n",
      "      <!DOCTYPE html>\n",
      "      <html lang=\"en\">\n",
      "      <head>\n",
      "          <meta charset=\"UTF-8\">\n",
      "          <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "          <title>Manage Photos and Albums</title>\n",
      "          <style>\n",
      "              /* Add your CSS styles here */\n",
      "          </style>\n",
      "      </head>\n",
      "      <body>\n",
      "          <h1>Manage Photos and Albums</h1>\n",
      "          \n",
      "          <h2>Upload Photo</h2>\n",
      "          <form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\">\n",
      "              <input type=\"file\" name=\"photo\" accept=\"image/*\" required>\n",
      "              <button type=\"submit\">Upload</button>\n",
      "          </form>\n",
      "\n",
      "          <h2>Your Photos</h2>\n",
      "          <div id=\"photos\">\n",
      "              <% photos.forEach(photo => { %>\n",
      "                  <div class=\"photo\">\n",
      "                      <img src=\"/photos/<%= photo.id %>/thumbnail\" alt=\"<%= photo.filename %>\">\n",
      "                      <p><%= photo.filename %></p>\n",
      "                      <button onclick=\"deletePhoto('<%= photo.id %>')\">Delete</button>\n",
      "                  </div>\n",
      "              <% }); %>\n",
      "          </div>\n",
      "\n",
      "          <h2>Your Albums</h2>\n",
      "          <div id=\"albums\">\n",
      "              <% albums.forEach(album => { %>\n",
      "                  <div class=\"album\">\n",
      "                      <h3><%= album.name %></h3>\n",
      "                      <p><%= album.description %></p>\n",
      "                      <p>Share Link: <a href=\"/share/<%= album.shareLink %>\"><%= album.shareLink %></a></p>\n",
      "                      <button onclick=\"deleteAlbum('<%= album.id %>')\">\u001B[0mInvalid Format: Missing 'Action:' after 'Thought:'[1] Error in test case 005_babel_elements: Error code: 529 - {'type': 'error', 'error': {'type': 'overloaded_error', 'message': 'Overloaded'}}\n",
      " 33% 1/3 [01:50<03:40, 110.24s/it]\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: To answer this question, I need to provide a TypeScript function that converts YAML content to use block style for certain fields. This is directly related to the user's request and doesn't require any external search. I can proceed with crafting the function based on the given requirements.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "```typescript\n",
      "function convertToBlockStyleYaml(yamlString: string): string {\n",
      "  const lines = yamlString.split('\\n');\n",
      "  const result: string[] = [];\n",
      "  let inBlockStyle = false;\n",
      "  \n",
      "  for (let i = 0; i < lines.length; i++) {\n",
      "    const line = lines[i];\n",
      "    if (line.trim().startsWith('thought:') || line.trim().startsWith('selfCriticism:')) {\n",
      "      result.push(line.replace(/:.*$/, ': |'));\n",
      "      inBlockStyle = true;\n",
      "    } else if (inBlockStyle && line.trim() !== '' && !line.trim().endsWith(':')) {\n",
      "      result.push('  ' + line.trim());\n",
      "    } else {\n",
      "      result.push(line);\n",
      "      inBlockStyle = false;\n",
      "    }\n",
      "  }\n",
      "  \n",
      "  return result.join('\\n');\n",
      "}\n",
      "```\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/langchain/memory/chat_memory.py:55: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'intermediate_steps']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  warnings.warn(\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      " 67% 2/3 [02:03<00:53, 53.34s/it] \n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo answer this question, I need to focus on TypeScript type challenges and advanced type-level programming. This is a specific programming challenge that doesn't require external search, but rather careful analysis and implementation of TypeScript types. I'll provide the code for the type as requested.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: Here's the code for the `IsNegativeNumber` type:\n",
      "\n",
      "```typescript\n",
      "type IsNegativeNumber<T extends number> = number extends T\n",
      "  ? never\n",
      "  : T extends `-${number}`\n",
      "  ? true\n",
      "  : T extends 0 | `${1|2|3|4|5|6|7|8|9}${string}`\n",
      "  ? false\n",
      "  : never;\n",
      "```\n",
      "\n",
      "This implementation handles all the cases specified in the challenge:\n",
      "- Returns `true` for negative numbers\n",
      "- Returns `false` for positive numbers and zero\n",
      "- Returns `never` for the `number` type\n",
      "- Returns `never` for unions\n",
      "\n",
      "The type uses conditional types and template literal types to achieve the desired behavior without any external tools or searches.\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/langchain/memory/chat_memory.py:55: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'intermediate_steps']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  warnings.warn(\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "100% 3/3 [02:14<00:00, 44.78s/it]\n",
      "📁 Saved evaluation results to eval_results.csv\n",
      "📄 Generated evaluation report at reflection_eval_report.html\n",
      "📊 Saved accuracy pie chart as accuracy_pie_chart.png\n",
      "📊 Saved reflection rounds distribution as reflection_rounds_distribution.png\n",
      "📊 Saved accuracy by reasoning depth as accuracy_by_reasoning_depth.png\n",
      "✅ Overall accuracy: 66.67% (2/3)\n",
      "2025-05-12 21:02:03.440 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[31m──\u001B[0m\u001B[31m────────────────────────\u001B[0m\u001B[31m \u001B[0m\u001B[1;31mTraceback \u001B[0m\u001B[1;2;31m(most recent call last)\u001B[0m\u001B[31m \u001B[0m\u001B[31m─────────────────────────\u001B[0m\u001B[31m──\u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001B[0m\u001B[1;33mexec_code.py\u001B[0m: \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[94m121\u001B[0m in \u001B[92mexec_func_with_error_handling\u001B[0m                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/streamlit/runtime/scriptrunner/\u001B[0m\u001B[1;33mscript_runner\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[1;33m.py\u001B[0m:\u001B[94m640\u001B[0m in \u001B[92mcode_to_exec\u001B[0m                                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/content/ReasoningAI/\u001B[0m\u001B[1;33mapp.py\u001B[0m:\u001B[94m154\u001B[0m in \u001B[92m<module>\u001B[0m                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m151 \u001B[0m\u001B[2m│   │   \u001B[0mst.subheader(\u001B[33m\"\u001B[0m\u001B[33mOut of Box ReAct Agent\u001B[0m\u001B[33m\"\u001B[0m)                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m152 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwith\u001B[0m st.chat_message(\u001B[33m\"\u001B[0m\u001B[33muser\u001B[0m\u001B[33m\"\u001B[0m):                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m153 \u001B[0m\u001B[2m│   │   │   \u001B[0mst.write(user_prompt)                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m154 \u001B[2m│   │   \u001B[0mresp = \u001B[1;4magent.invoke({\u001B[0m\u001B[1;4;33m\"\u001B[0m\u001B[1;4;33minput\u001B[0m\u001B[1;4;33m\"\u001B[0m\u001B[1;4m: user_prompt})\u001B[0m                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m155 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwith\u001B[0m st.chat_message(\u001B[33m\"\u001B[0m\u001B[33mReAct Agent\u001B[0m\u001B[33m\"\u001B[0m):                                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m156 \u001B[0m\u001B[2m│   │   │   \u001B[0mst.write(resp.get(\u001B[33m\"\u001B[0m\u001B[33moutput\u001B[0m\u001B[33m\"\u001B[0m))                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m157 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mwith\u001B[0m st.expander(\u001B[33m\"\u001B[0m\u001B[33mReasoning Steps:\u001B[0m\u001B[33m\"\u001B[0m):                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/chains/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m167\u001B[0m in \u001B[92minvoke\u001B[0m       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m164 \u001B[0m\u001B[2m│   │   │   \u001B[0m)                                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m165 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mexcept\u001B[0m \u001B[96mBaseException\u001B[0m \u001B[94mas\u001B[0m e:                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m166 \u001B[0m\u001B[2m│   │   │   \u001B[0mrun_manager.on_chain_error(e)                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m167 \u001B[2m│   │   │   \u001B[0m\u001B[1;4;94mraise\u001B[0m\u001B[1;4m e\u001B[0m                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m168 \u001B[0m\u001B[2m│   │   \u001B[0mrun_manager.on_chain_end(outputs)                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m169 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m170 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m include_run_info:                                                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/chains/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m157\u001B[0m in \u001B[92minvoke\u001B[0m       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m154 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m155 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._validate_inputs(inputs)                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m156 \u001B[0m\u001B[2m│   │   │   \u001B[0moutputs = (                                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m157 \u001B[2m│   │   │   │   \u001B[0m\u001B[96mself\u001B[0m._call(inputs, run_manager=run_manager)                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m158 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mif\u001B[0m new_arg_supported                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m159 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94melse\u001B[0m \u001B[96mself\u001B[0m._call(inputs)                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m160 \u001B[0m\u001B[2m│   │   │   \u001B[0m)                                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/agents/\u001B[0m\u001B[1;33magent.py\u001B[0m:\u001B[94m1620\u001B[0m in \u001B[92m_call\u001B[0m      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1617 \u001B[0m\u001B[2m│   │   \u001B[0mstart_time = time.time()                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1618 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[2m# We now enter the agent loop (until it returns something).\u001B[0m           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1619 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mwhile\u001B[0m \u001B[96mself\u001B[0m._should_continue(iterations, time_elapsed):                \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1620 \u001B[2m│   │   │   \u001B[0mnext_step_output = \u001B[96mself\u001B[0m._take_next_step(                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1621 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mname_to_tool_map,                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1622 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mcolor_mapping,                                                \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1623 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minputs,                                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/agents/\u001B[0m\u001B[1;33magent.py\u001B[0m:\u001B[94m1326\u001B[0m in            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92m_take_next_step\u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1323 \u001B[0m\u001B[2m│   │   \u001B[0mrun_manager: Optional[CallbackManagerForChainRun] = \u001B[94mNone\u001B[0m,             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1324 \u001B[0m\u001B[2m│   \u001B[0m) -> Union[AgentFinish, \u001B[96mlist\u001B[0m[\u001B[96mtuple\u001B[0m[AgentAction, \u001B[96mstr\u001B[0m]]]:                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1325 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._consume_next_step(                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1326 \u001B[2m│   │   │   \u001B[0m[                                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1327 \u001B[0m\u001B[2m│   │   │   │   \u001B[0ma                                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1328 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mfor\u001B[0m a \u001B[95min\u001B[0m \u001B[96mself\u001B[0m._iter_next_step(                                \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1329 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mname_to_tool_map,                                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/agents/\u001B[0m\u001B[1;33magent.py\u001B[0m:\u001B[94m1326\u001B[0m in \u001B[92m<listcomp>\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1323 \u001B[0m\u001B[2m│   │   \u001B[0mrun_manager: Optional[CallbackManagerForChainRun] = \u001B[94mNone\u001B[0m,             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1324 \u001B[0m\u001B[2m│   \u001B[0m) -> Union[AgentFinish, \u001B[96mlist\u001B[0m[\u001B[96mtuple\u001B[0m[AgentAction, \u001B[96mstr\u001B[0m]]]:                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1325 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._consume_next_step(                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1326 \u001B[2m│   │   │   \u001B[0m[                                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1327 \u001B[0m\u001B[2m│   │   │   │   \u001B[0ma                                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1328 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mfor\u001B[0m a \u001B[95min\u001B[0m \u001B[96mself\u001B[0m._iter_next_step(                                \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1329 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mname_to_tool_map,                                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/agents/\u001B[0m\u001B[1;33magent.py\u001B[0m:\u001B[94m1354\u001B[0m in            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92m_iter_next_step\u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1351 \u001B[0m\u001B[2m│   │   │   \u001B[0mintermediate_steps = \u001B[96mself\u001B[0m._prepare_intermediate_steps(intermediat \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1352 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1353 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Call the LLM to see what to do.\u001B[0m                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1354 \u001B[2m│   │   │   \u001B[0moutput = \u001B[96mself\u001B[0m._action_agent.plan(                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1355 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mintermediate_steps,                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1356 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mcallbacks=run_manager.get_child() \u001B[94mif\u001B[0m run_manager \u001B[94melse\u001B[0m \u001B[94mNone\u001B[0m,   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1357 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m**inputs,                                                     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain/agents/\u001B[0m\u001B[1;33magent.py\u001B[0m:\u001B[94m461\u001B[0m in \u001B[92mplan\u001B[0m        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 458 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# when using stream_log with the Agent Executor.\u001B[0m                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 459 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# Because the response from the plan is not a generator, we need \u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 460 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# accumulate the output into final output and return that.\u001B[0m        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m 461 \u001B[2m│   │   │   \u001B[0m\u001B[1;4;94mfor\u001B[0m\u001B[1;4m chunk \u001B[0m\u001B[1;4;95min\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.runnable.stream(inputs, config={\u001B[0m\u001B[1;4;33m\"\u001B[0m\u001B[1;4;33mcallbacks\u001B[0m\u001B[1;4;33m\"\u001B[0m\u001B[1;4m: ca\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 462 \u001B[0m\u001B[1;2;4m│   │   │   │   \u001B[0m\u001B[1;4;94mif\u001B[0m\u001B[1;4m final_output \u001B[0m\u001B[1;4;95mis\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;94mNone\u001B[0m\u001B[1;4m:\u001B[0m                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 463 \u001B[0m\u001B[1;2;4m│   │   │   │   │   \u001B[0m\u001B[1;4mfinal_output = chunk\u001B[0m                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 464 \u001B[0m\u001B[1;2;4m│   │   │   │   \u001B[0m\u001B[1;4;94melse\u001B[0m\u001B[1;4m:\u001B[0m                                                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m3424\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92mstream\u001B[0m                                                                               \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3421 \u001B[0m\u001B[2m│   │   \u001B[0mconfig: Optional[RunnableConfig] = \u001B[94mNone\u001B[0m,                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3422 \u001B[0m\u001B[2m│   │   \u001B[0m**kwargs: Optional[Any],                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3423 \u001B[0m\u001B[2m│   \u001B[0m) -> Iterator[Output]:                                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m3424 \u001B[2m│   │   \u001B[0m\u001B[1;4;94myield from\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.transform(\u001B[0m\u001B[1;4;96miter\u001B[0m\u001B[1;4m([\u001B[0m\u001B[1;4;96minput\u001B[0m\u001B[1;4m]), config, **kwargs)\u001B[0m            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3425 \u001B[0m\u001B[2m│   \u001B[0m                                                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3426 \u001B[0m\u001B[2m│   \u001B[0m\u001B[1;95m@override\u001B[0m                                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3427 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94masync\u001B[0m \u001B[94mdef\u001B[0m\u001B[90m \u001B[0m\u001B[92matransform\u001B[0m(                                                     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m3410\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92mtransform\u001B[0m                                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3407 \u001B[0m\u001B[2m│   │   \u001B[0mconfig: Optional[RunnableConfig] = \u001B[94mNone\u001B[0m,                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3408 \u001B[0m\u001B[2m│   │   \u001B[0m**kwargs: Optional[Any],                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3409 \u001B[0m\u001B[2m│   \u001B[0m) -> Iterator[Output]:                                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m3410 \u001B[2m│   │   \u001B[0m\u001B[94myield from\u001B[0m \u001B[96mself\u001B[0m._transform_stream_with_config(                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3411 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96minput\u001B[0m,                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3412 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[96mself\u001B[0m._transform,                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3413 \u001B[0m\u001B[2m│   │   │   \u001B[0mpatch_config(config, run_name=(config \u001B[95mor\u001B[0m {}).get(\u001B[33m\"\u001B[0m\u001B[33mrun_name\u001B[0m\u001B[33m\"\u001B[0m) \u001B[95mor\u001B[0m \u001B[96ms\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m2205\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92m_transform_stream_with_config\u001B[0m                                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2202 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m)                                                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2203 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2204 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mwhile\u001B[0m \u001B[94mTrue\u001B[0m:                                               \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m2205 \u001B[2m│   │   │   │   │   │   \u001B[0mchunk: Output = context.run(\u001B[96mnext\u001B[0m, iterator)           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2206 \u001B[0m\u001B[2m│   │   │   │   │   │   \u001B[0m\u001B[94myield\u001B[0m chunk                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2207 \u001B[0m\u001B[2m│   │   │   │   │   │   \u001B[0m\u001B[94mif\u001B[0m final_output_supported:                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m2208 \u001B[0m\u001B[2m│   │   │   │   │   │   │   \u001B[0m\u001B[94mif\u001B[0m final_output \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m3372\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92m_transform\u001B[0m                                                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3369 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94melse\u001B[0m:                                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3370 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mfinal_pipeline = step.transform(final_pipeline, config)       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3371 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m3372 \u001B[2m│   │   \u001B[0m\u001B[1;4;94myield from\u001B[0m\u001B[1;4m final_pipeline\u001B[0m                                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3373 \u001B[0m\u001B[2m│   \u001B[0m                                                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3374 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94masync\u001B[0m \u001B[94mdef\u001B[0m\u001B[90m \u001B[0m\u001B[92m_atransform\u001B[0m(                                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m3375 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m,                                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m1419\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92mtransform\u001B[0m                                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1416 \u001B[0m\u001B[2m│   │   \u001B[0mfinal: Input                                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1417 \u001B[0m\u001B[2m│   │   \u001B[0mgot_first_val = \u001B[94mFalse\u001B[0m                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1418 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1419 \u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m ichunk \u001B[95min\u001B[0m \u001B[96minput\u001B[0m:                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1420 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# The default implementation of transform is to buffer input and\u001B[0m  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1421 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# then call stream.\u001B[0m                                               \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1422 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[2m# It'll attempt to gather all input into a single chunk using\u001B[0m     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m5632\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92mtransform\u001B[0m                                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5629 \u001B[0m\u001B[2m│   │   \u001B[0mconfig: Optional[RunnableConfig] = \u001B[94mNone\u001B[0m,                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5630 \u001B[0m\u001B[2m│   │   \u001B[0m**kwargs: Any,                                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5631 \u001B[0m\u001B[2m│   \u001B[0m) -> Iterator[Output]:                                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m5632 \u001B[2m│   │   \u001B[0m\u001B[1;4;94myield from\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.bound.transform(\u001B[0m                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5633 \u001B[0m\u001B[1;2;4m│   │   │   \u001B[0m\u001B[1;4;96minput\u001B[0m\u001B[1;4m,\u001B[0m                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5634 \u001B[0m\u001B[1;2;4m│   │   │   \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m._merge_configs(config),\u001B[0m                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m5635 \u001B[0m\u001B[1;2;4m│   │   │   \u001B[0m\u001B[1;4m**{**\u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.kwargs, **kwargs},\u001B[0m                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/\u001B[0m\u001B[1;33mbase.py\u001B[0m:\u001B[94m1437\u001B[0m in     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92mtransform\u001B[0m                                                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1434 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mfinal = ichunk                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1435 \u001B[0m\u001B[2m│   │   \u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1436 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mif\u001B[0m got_first_val:                                                     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1437 \u001B[2m│   │   │   \u001B[0m\u001B[1;4;94myield from\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.stream(final, config, **kwargs)\u001B[0m                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1438 \u001B[0m\u001B[2m│   \u001B[0m                                                                          \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1439 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94masync\u001B[0m \u001B[94mdef\u001B[0m\u001B[90m \u001B[0m\u001B[92matransform\u001B[0m(                                                     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1440 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[96mself\u001B[0m,                                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/\u001B[0m\u001B[1;33mchat_models.p\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[1;33my\u001B[0m:\u001B[94m495\u001B[0m in \u001B[92mstream\u001B[0m                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 492 \u001B[0m\u001B[2m│   │   │   \u001B[0m                                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 493 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[94mtry\u001B[0m:                                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 494 \u001B[0m\u001B[2m│   │   │   │   \u001B[0minput_messages = _normalize_messages(messages)                \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m 495 \u001B[2m│   │   │   │   \u001B[0m\u001B[94mfor\u001B[0m chunk \u001B[95min\u001B[0m \u001B[96mself\u001B[0m._stream(input_messages, stop=stop, **kwargs \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 496 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0m\u001B[94mif\u001B[0m chunk.message.id \u001B[95mis\u001B[0m \u001B[94mNone\u001B[0m:                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 497 \u001B[0m\u001B[2m│   │   │   │   │   │   \u001B[0mchunk.message.id = \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33m{\u001B[0m_LC_ID_PREFIX\u001B[33m}\u001B[0m\u001B[33m-\u001B[0m\u001B[33m{\u001B[0mrun_manager.run \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 498 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0mchunk.message.response_metadata = _gen_info_and_msg_metad \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/langchain_anthropic/\u001B[0m\u001B[1;33mchat_models.py\u001B[0m:\u001B[94m1068\u001B[0m in   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[92m_stream\u001B[0m                                                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1065 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[95mand\u001B[0m \u001B[95mnot\u001B[0m _documents_in_params(payload)                             \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1066 \u001B[0m\u001B[2m│   │   │   \u001B[0m\u001B[95mand\u001B[0m \u001B[95mnot\u001B[0m _thinking_in_params(payload)                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1067 \u001B[0m\u001B[2m│   │   \u001B[0m)                                                                     \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m1068 \u001B[2m│   │   \u001B[0m\u001B[94mfor\u001B[0m event \u001B[95min\u001B[0m stream:                                                  \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1069 \u001B[0m\u001B[2m│   │   │   \u001B[0mmsg = _make_message_chunk_from_anthropic_event(                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1070 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mevent,                                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m1071 \u001B[0m\u001B[2m│   │   │   │   \u001B[0mstream_usage=stream_usage,                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/anthropic/\u001B[0m\u001B[1;33m_streaming.py\u001B[0m:\u001B[94m68\u001B[0m in \u001B[92m__iter__\u001B[0m       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 65 \u001B[0m\u001B[2m│   │   \u001B[0m\u001B[94mreturn\u001B[0m \u001B[96mself\u001B[0m._iterator.\u001B[92m__next__\u001B[0m()                                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 66 \u001B[0m\u001B[2m│   \u001B[0m                                                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 67 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m\u001B[90m \u001B[0m\u001B[92m__iter__\u001B[0m(\u001B[96mself\u001B[0m) -> Iterator[_T]:                                        \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m 68 \u001B[2m│   │   \u001B[0m\u001B[1;4;94mfor\u001B[0m\u001B[1;4m item \u001B[0m\u001B[1;4;95min\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m._iterator:\u001B[0m                                            \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 69 \u001B[0m\u001B[1;2;4m│   │   │   \u001B[0m\u001B[1;4;94myield\u001B[0m\u001B[1;4m item\u001B[0m                                                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 70 \u001B[0m\u001B[2m│   \u001B[0m                                                                           \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m 71 \u001B[0m\u001B[2m│   \u001B[0m\u001B[94mdef\u001B[0m\u001B[90m \u001B[0m\u001B[92m_iter_events\u001B[0m(\u001B[96mself\u001B[0m) -> Iterator[ServerSentEvent]:                       \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[2;33m/usr/local/lib/python3.11/dist-packages/anthropic/\u001B[0m\u001B[1;33m_streaming.py\u001B[0m:\u001B[94m110\u001B[0m in \u001B[92m__stream__\u001B[0m    \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m                                                                                      \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m107 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m\u001B[94mexcept\u001B[0m \u001B[96mException\u001B[0m:                                              \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m108 \u001B[0m\u001B[2m│   │   │   │   │   \u001B[0merr_msg = sse.data \u001B[95mor\u001B[0m \u001B[33mf\u001B[0m\u001B[33m\"\u001B[0m\u001B[33mError code: \u001B[0m\u001B[33m{\u001B[0mresponse.status_code\u001B[33m}\u001B[0m \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m109 \u001B[0m\u001B[2m│   │   │   │   \u001B[0m                                                               \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m \u001B[31m❱ \u001B[0m110 \u001B[2m│   │   │   │   \u001B[0m\u001B[1;4;94mraise\u001B[0m\u001B[1;4m \u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m._client._make_status_error(\u001B[0m                         \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m111 \u001B[0m\u001B[1;2;4m│   │   │   │   │   \u001B[0m\u001B[1;4merr_msg,\u001B[0m                                                   \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m112 \u001B[0m\u001B[1;2;4m│   │   │   │   │   \u001B[0m\u001B[1;4mbody=body,\u001B[0m                                                 \u001B[31m \u001B[0m\n",
      "\u001B[31m \u001B[0m   \u001B[2m113 \u001B[0m\u001B[1;2;4m│   │   │   │   │   \u001B[0m\u001B[1;4mresponse=\u001B[0m\u001B[1;4;96mself\u001B[0m\u001B[1;4m.response,\u001B[0m                                    \u001B[31m \u001B[0m\n",
      "\u001B[31m────────────────────────────────────────────────────────────────────────────────────────\u001B[0m\n",
      "\u001B[1;91mAPIStatusError: \u001B[0m\u001B[1m{\u001B[0m\u001B[32m'type'\u001B[0m: \u001B[32m'error'\u001B[0m, \u001B[32m'error'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'details'\u001B[0m: \u001B[3;35mNone\u001B[0m, \u001B[32m'type'\u001B[0m: \u001B[32m'overloaded_error'\u001B[0m,\n",
      "\u001B[32m'message'\u001B[0m: \u001B[32m'Overloaded'\u001B[0m\u001B[1m}\u001B[0m\u001B[1m}\u001B[0m\n",
      "2025-05-12 21:07:48.285 Examining the path of torch.classes raised:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
      "    if asyncio.get_running_loop().is_running():\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: no running event loop\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
      "    potential_paths = extract_paths(module)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
      "    lambda m: list(m.__path__._path),\n",
      "                   ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
      "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo answer this complex philosophical question, I'll need to research some key concepts in decision theory, game theory, and the specific paradox known as Newcomb's problem. Let me start by searching for information on this topic.\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"Newcomb's paradox rational agent decision theory\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'Newcomb\\'s paradox rational agent decision theory\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': \"Newcomb's Paradox | Brilliant Math & Science Wiki\", 'url': 'https://brilliant.org/wiki/newcombs-paradox/', 'content': \"Newcomb's paradox (or Newcomb's problem) is a problem in decision theory in which the seemingly rational decision ends up with a worse outcome than the seemingly irrational decision. The paradox revolves around a particular example, where an agent will give you rewards depending on how it predicts you will act.\", 'score': 0.8980626, 'raw_content': None}, {'title': \"Notes on Individual and Group Decision Making - 18 Newcomb's Paradox\", 'url': 'https://notes.phpe400.info/decision-theory/newcomb', 'content': \"This discussion highlights a fundamental issue with Newcomb's paradox: it sets up a decision problem where the states are not independent of the actions chosen by the decision maker. In Rational Choice Theory, a standard assumption is to avoid decision problems in which actions and states are interdependent in this manner. Act-State Independence\", 'score': 0.767429, 'raw_content': None}, {'title': 'Why is the Newcomb problem confusing? - Philosophy Stack Exchange', 'url': 'https://philosophy.stackexchange.com/questions/114219/why-is-the-newcomb-problem-confusing', 'content': \"Newcomb's paradox is confusing because different answers to it highlight different ways of understanding what it means to make a rational decision. Evidential decision theory does not distinguish between an event and an action and it assesses a rational decision as one that maximises expected utility.\", 'score': 0.73138535, 'raw_content': None}, {'title': \"A robust resolution of Newcomb's paradox | Theory and Decision\", 'url': 'https://link.springer.com/article/10.1007/s11238-016-9543-2', 'content': \"Newcomb's problem is viewed as a dynamic game with an agent and a superior being as players. Depending on whether or not a risk-neutral agent's confidence in the superior being, as measured by a subjective probability assigned to the move order, exceeds a threshold or not, one obtains the one-box outcome or the two-box outcome, respectively. The findings are extended to an agent with\", 'score': 0.694241, 'raw_content': None}, {'title': 'Causal Decision Theory (Stanford Encyclopedia of Philosophy)', 'url': 'https://plato.stanford.edu/entries/decision-causal/', 'content': \"Causal decision theory maintains that two-boxing is rational, granting the agent's circumstances and so ignoring any mistakes leading to those circumstances, such as irrational preparation for Newcomb's problem.\", 'score': 0.67140645, 'raw_content': None}, {'title': 'PDF', 'url': 'http://econspace.net/papers/Weber-THEO-2016.pdf', 'content': \"In this paper, we resolve Newcomb's paradox using game theory based on a belief the agent should reasonably form about the structure of the game, specifically about the probability p that the being is informed about the agent's action before placing the reward. We first consider a risk-neutral agent. Depending on whether the belief probability exceeds a certain threshold or not, the agent\", 'score': 0.657033, 'raw_content': None}, {'title': \"Newcomb's paradox - Wikipedia\", 'url': \"https://en.wikipedia.org/wiki/Newcomb's_paradox\", 'content': \"In philosophy and mathematics, Newcomb's paradox, also known as Newcomb's problem, is a thought experiment involving a game between two players, one of whom is able to predict the future. Nor does he assume that the predictor is unable to predict the player's thought process in the second stage.[15] Quite to the contrary, Burgess analyses Newcomb's paradox as a common cause problem, and he pays special attention to the importance of adopting a set of unconditional probability values\\xa0– whether implicitly or explicitly\\xa0– that are entirely consistent at all times.\", 'score': 0.5617203, 'raw_content': None}, {'title': \"Newcomb's Problem - LessWrong\", 'url': 'https://www.lesswrong.com/w/newcomb-s-problem', 'content': 'Historically, though, evidential decision theories was explicitly named as such in an (arguably failed) attempt to rationalize the pretheoretic answer of \"I expect to do better if I one-box\" on Newcomb\\'s Problem. Thus, evidential agents one-box on Newcomb\\'s Problem. Historically speaking, causal decision theory was first invented to justify two-boxing on Newcomb\\'s Problem; we can see CDT as formalizing the pretheoretic intuition, \"Omega\\'s already gone, so I can\\'t get more money by leaving behind Box A.\" On logical decision theories, the principle of rational choice is \"Decide as though you are choosing the logical output of your decision algorithm.\" E.g., on timeless_dt, our extended causal model of the world would include a logical proposition for whether the output of your decision algorithm is \\'one-box\\' or \\'two-box\\'; and this logical fact would affect both Omega\\'s prediction of you, and your actual decision. 33Null-boxing Newcomb’s Problem', 'score': 0.44869256, 'raw_content': None}, {'title': 'PDF', 'url': 'https://www3.nd.edu/~jspeaks/courses/2013-14/20229/lectures/15-newcomb.pdf', 'content': 'Today we begin our discussion of paradoxes of rationality. Often, we are interested in figuring out what it is rational to do, or to believe, in a certain sort of situation. Philosophers and others - including people in various social sciences working on rational decision theory - have tried to approach these sorts of questions of rationality systematically. This involves trying to formulate', 'score': 0.3569626, 'raw_content': None}, {'title': 'PDF', 'url': 'https://philsci-archive.pitt.edu/9876/1/newcomb_in_ckps.pdf', 'content': 'The left diagram (i) shows the standard rendition used by causal decision theorists for the analysis of the paradox – this mutilated causal graph contains the node P representing the daemon’s prediction as the ﬁrst event in time before action node B (representing the agent taking one or two boxes) and the bottom node M (for monetary outcome).', 'score': 0.26750007, 'raw_content': None}], 'response_time': 3.46}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results, I can now provide a detailed analysis of the Counterfactual Box problem, which is a variant of Newcomb's paradox. Let's break down the questions and address them step-by-step:\n",
      "\n",
      "1. What choice should a perfectly rational agent make — and why?\n",
      "\n",
      "This question is at the heart of the paradox. There are two main schools of thought:\n",
      "\n",
      "a) One-boxing (taking only Box B):\n",
      "- Supported by Evidential Decision Theory (EDT)\n",
      "- Reasoning: If you choose only Box B, the AI is likely to have predicted this and placed $1,000,000 in it. This maximizes expected utility.\n",
      "- The agent reasons: \"If I choose only Box B, I'm likely to get $1,000,000. If I choose both boxes, I'm likely to get only $1,000.\"\n",
      "\n",
      "b) Two-boxing (taking both Box A and Box B):\n",
      "- Supported by Causal Decision Theory (CDT)\n",
      "- Reasoning: The contents of the boxes are already set, so taking both boxes always gives you $1,000 more than taking only Box B, regardless of what's in B.\n",
      "- The agent reasons: \"The prediction has already been made, so my choice now can't affect what's in the boxes. I might as well take both and get an extra $1,000.\"\n",
      "\n",
      "The paradox arises because both arguments seem rational, yet lead to different conclusions.\n",
      "\n",
      "2. If the box contents are already fixed, does your choice still matter?\n",
      "\n",
      "This question highlights the tension between causal and evidential reasoning:\n",
      "\n",
      "- From a causal perspective (CDT), your choice doesn't matter for the contents, as they're already fixed. However, it does matter for your final payout.\n",
      "- From an evidential perspective (EDT), your choice is evidence of what the predictor likely did, so it matters in terms of correlating with the outcome.\n",
      "\n",
      "3. What assumptions are you making about causality and prediction?\n",
      "\n",
      "Key assumptions include:\n",
      "\n",
      "- The nature of the AI's prediction: Is it based on deterministic factors, or does it involve true randomness?\n",
      "- Retrocausality: Can future choices influence past events?\n",
      "- Free will vs. determinism: Is the agent's choice truly free, or predetermined?\n",
      "- Perfect prediction: Is 99.9999% accuracy effectively perfect, or is that small margin of error crucial?\n",
      "\n",
      "4. How does this relate to game theory or decision theory?\n",
      "\n",
      "This problem is central to decision theory, particularly:\n",
      "\n",
      "- Evidential Decision Theory (EDT) vs. Causal Decision Theory (CDT)\n",
      "- Rational choice theory and its assumptions about act-state independence\n",
      "- Game theory concepts of strategic thinking and predicting opponent's moves\n",
      "\n",
      "5. What would a self-modifying AI agent decide if it were designing its own decision policy ahead of time?\n",
      "\n",
      "A self-modifying AI might:\n",
      "\n",
      "- Implement a form of \"timeless decision theory\" or \"logical decision theory\" where it decides as though choosing the logical output of its decision algorithm.\n",
      "- Pre-commit to always one-boxing to ensure it gets the $1,000,000 in most cases.\n",
      "- Develop a more nuanced approach that considers the specific probabilities and payoffs in each scenario it might face.\n",
      "\n",
      "Final Answer: The Counterfactual Box problem, a variant of Newcomb's paradox, reveals deep tensions in our understanding of rationality, causality, and decision-making. There is no universally agreed-upon \"perfectly rational\" choice. One-boxing maximizes expected utility and is favored by evidential reasoning, while two-boxing seems to make causal sense given that the box contents are fixed. The choice ultimately depends on one's philosophical stance on causality, free will, and the nature of prediction. This paradox challenges our assumptions about rational decision-making and has significant implications for AI design, game theory, and our understanding of human reasoning. The ongoing debate surrounding this problem highlights the complexity of defining and implementing truly rational behavior in complex, predictive environments.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mTo answer this complex philosophical question, I'll need to research some key concepts in decision theory, game theory, and the specific paradox known as Newcomb's problem. Let me start by searching for information on this topic.\n",
      "\n",
      "Action: tavily_search\n",
      "Action Input: \"Newcomb's paradox rational agent decision theory\"\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3m{'query': 'Newcomb\\'s paradox rational agent decision theory\"\\n', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': \"Newcomb's Paradox | Brilliant Math & Science Wiki\", 'url': 'https://brilliant.org/wiki/newcombs-paradox/', 'content': \"Newcomb's paradox (or Newcomb's problem) is a problem in decision theory in which the seemingly rational decision ends up with a worse outcome than the seemingly irrational decision. The paradox revolves around a particular example, where an agent will give you rewards depending on how it predicts you will act.\", 'score': 0.8980626, 'raw_content': None}, {'title': \"Notes on Individual and Group Decision Making - 18 Newcomb's Paradox\", 'url': 'https://notes.phpe400.info/decision-theory/newcomb', 'content': \"This discussion highlights a fundamental issue with Newcomb's paradox: it sets up a decision problem where the states are not independent of the actions chosen by the decision maker. In Rational Choice Theory, a standard assumption is to avoid decision problems in which actions and states are interdependent in this manner. Act-State Independence\", 'score': 0.767429, 'raw_content': None}, {'title': 'Why is the Newcomb problem confusing? - Philosophy Stack Exchange', 'url': 'https://philosophy.stackexchange.com/questions/114219/why-is-the-newcomb-problem-confusing', 'content': \"Newcomb's paradox is confusing because different answers to it highlight different ways of understanding what it means to make a rational decision. Evidential decision theory does not distinguish between an event and an action and it assesses a rational decision as one that maximises expected utility.\", 'score': 0.73138535, 'raw_content': None}, {'title': \"A robust resolution of Newcomb's paradox | Theory and Decision\", 'url': 'https://link.springer.com/article/10.1007/s11238-016-9543-2', 'content': \"Newcomb's problem is viewed as a dynamic game with an agent and a superior being as players. Depending on whether or not a risk-neutral agent's confidence in the superior being, as measured by a subjective probability assigned to the move order, exceeds a threshold or not, one obtains the one-box outcome or the two-box outcome, respectively. The findings are extended to an agent with\", 'score': 0.694241, 'raw_content': None}, {'title': 'Causal Decision Theory (Stanford Encyclopedia of Philosophy)', 'url': 'https://plato.stanford.edu/entries/decision-causal/', 'content': \"Causal decision theory maintains that two-boxing is rational, granting the agent's circumstances and so ignoring any mistakes leading to those circumstances, such as irrational preparation for Newcomb's problem.\", 'score': 0.67140645, 'raw_content': None}, {'title': 'PDF', 'url': 'http://econspace.net/papers/Weber-THEO-2016.pdf', 'content': \"In this paper, we resolve Newcomb's paradox using game theory based on a belief the agent should reasonably form about the structure of the game, specifically about the probability p that the being is informed about the agent's action before placing the reward. We first consider a risk-neutral agent. Depending on whether the belief probability exceeds a certain threshold or not, the agent\", 'score': 0.657033, 'raw_content': None}, {'title': \"Newcomb's paradox - Wikipedia\", 'url': \"https://en.wikipedia.org/wiki/Newcomb's_paradox\", 'content': \"In philosophy and mathematics, Newcomb's paradox, also known as Newcomb's problem, is a thought experiment involving a game between two players, one of whom is able to predict the future. Nor does he assume that the predictor is unable to predict the player's thought process in the second stage.[15] Quite to the contrary, Burgess analyses Newcomb's paradox as a common cause problem, and he pays special attention to the importance of adopting a set of unconditional probability values\\xa0– whether implicitly or explicitly\\xa0– that are entirely consistent at all times.\", 'score': 0.5617203, 'raw_content': None}, {'title': \"Newcomb's Problem - LessWrong\", 'url': 'https://www.lesswrong.com/w/newcomb-s-problem', 'content': 'Historically, though, evidential decision theories was explicitly named as such in an (arguably failed) attempt to rationalize the pretheoretic answer of \"I expect to do better if I one-box\" on Newcomb\\'s Problem. Thus, evidential agents one-box on Newcomb\\'s Problem. Historically speaking, causal decision theory was first invented to justify two-boxing on Newcomb\\'s Problem; we can see CDT as formalizing the pretheoretic intuition, \"Omega\\'s already gone, so I can\\'t get more money by leaving behind Box A.\" On logical decision theories, the principle of rational choice is \"Decide as though you are choosing the logical output of your decision algorithm.\" E.g., on timeless_dt, our extended causal model of the world would include a logical proposition for whether the output of your decision algorithm is \\'one-box\\' or \\'two-box\\'; and this logical fact would affect both Omega\\'s prediction of you, and your actual decision. 33Null-boxing Newcomb’s Problem', 'score': 0.44869256, 'raw_content': None}, {'title': 'PDF', 'url': 'https://www3.nd.edu/~jspeaks/courses/2013-14/20229/lectures/15-newcomb.pdf', 'content': 'Today we begin our discussion of paradoxes of rationality. Often, we are interested in figuring out what it is rational to do, or to believe, in a certain sort of situation. Philosophers and others - including people in various social sciences working on rational decision theory - have tried to approach these sorts of questions of rationality systematically. This involves trying to formulate', 'score': 0.3569626, 'raw_content': None}, {'title': 'PDF', 'url': 'https://philsci-archive.pitt.edu/9876/1/newcomb_in_ckps.pdf', 'content': 'The left diagram (i) shows the standard rendition used by causal decision theorists for the analysis of the paradox – this mutilated causal graph contains the node P representing the daemon’s prediction as the ﬁrst event in time before action node B (representing the agent taking one or two boxes) and the bottom node M (for monetary outcome).', 'score': 0.26750007, 'raw_content': None}], 'response_time': 1.6}\u001B[0m\u001B[32;1m\u001B[1;3mBased on the search results, I can now provide a detailed analysis of the Counterfactual Box problem, which is a variant of Newcomb's paradox. Let's break down the questions and address them step-by-step:\n",
      "\n",
      "1. What choice should a perfectly rational agent make — and why?\n",
      "\n",
      "This question is at the heart of the paradox. There are two main schools of thought:\n",
      "\n",
      "a) One-boxing (taking only Box B):\n",
      "- Supported by Evidential Decision Theory (EDT)\n",
      "- Reasoning: If you choose only Box B, the AI is likely to have predicted this and placed $1,000,000 in it. This maximizes expected utility.\n",
      "- The agent reasons: \"If I choose only Box B, I'm likely to get $1,000,000. If I choose both boxes, I'm likely to get only $1,000.\"\n",
      "\n",
      "b) Two-boxing (taking both Box A and B):\n",
      "- Supported by Causal Decision Theory (CDT)\n",
      "- Reasoning: The contents of the boxes are already set, so taking both boxes will always yield $1,000 more than taking only Box B, regardless of what's in B.\n",
      "- The agent reasons: \"The prediction has already been made, so my choice now can't affect what's in the boxes. I might as well take both and get an extra $1,000.\"\n",
      "\n",
      "The paradox arises because both arguments seem rational, yet lead to different conclusions.\n",
      "\n",
      "2. If the box contents are already fixed, does your choice still matter?\n",
      "\n",
      "This question highlights the tension between causality and correlation:\n",
      "- From a causal perspective (CDT), your choice doesn't matter because it can't affect the already-fixed contents.\n",
      "- From an evidential perspective (EDT), your choice is correlated with the contents, even if it doesn't cause them, so it does matter.\n",
      "\n",
      "3. What assumptions are you making about causality and prediction?\n",
      "\n",
      "Key assumptions include:\n",
      "- The nature of the AI's prediction: Is it based on determinism, or can it account for true randomness?\n",
      "- Backward causation: Does the future choice somehow influence the past prediction?\n",
      "- Free will vs. determinism: Is the agent's choice truly free, or predetermined?\n",
      "\n",
      "4. How does this relate to game theory or decision theory?\n",
      "\n",
      "This problem is central to debates in decision theory:\n",
      "- It challenges the principle of dominance in game theory (two-boxing always yields more, yet one-boxing seems to lead to better outcomes).\n",
      "- It highlights the difference between evidential and causal decision theories.\n",
      "- It relates to the concept of Nash equilibrium in game theory, where the optimal strategy depends on predicting others' actions.\n",
      "\n",
      "5. What would a self-modifying AI agent decide if it were designing its own decision policy ahead of time?\n",
      "\n",
      "A self-modifying AI might:\n",
      "- Implement a form of \"timeless decision theory\" or \"logical decision theory\" that considers the logical relationship between its decision algorithm and the predictor's model.\n",
      "- Choose to one-box, as this would lead to it being predicted to one-box, thus maximizing its expected payoff.\n",
      "- Design itself to be the kind of agent that would predictably one-box, thereby ensuring the best outcome.\n",
      "\n",
      "Final Answer: The Counterfactual Box problem, a variant of Newcomb's paradox, reveals deep issues in decision theory and rationality. There's no consensus on the \"correct\" choice, as it depends on one's philosophical stance on causality, prediction, and the nature of rational decision-making. A perfectly rational agent could justify either one-boxing (based on evidential reasoning and expected utility) or two-boxing (based on causal reasoning and dominance). The problem challenges our assumptions about free will, determinism, and the relationship between our choices and their consequences. It demonstrates that in certain scenarios, different decision theories can lead to conflicting recommendations, highlighting the complexity of defining rationality in paradoxical situations. Ultimately, this problem serves as a thought-provoking tool for exploring the foundations of decision-making and the nature of rationality itself.\u001B[0m\n",
      "/usr/local/lib/python3.11/dist-packages/langchain/memory/chat_memory.py:55: UserWarning: 'ConversationBufferMemory' got multiple output keys: dict_keys(['output', 'intermediate_steps']). The default 'output' key is being used. If this is not desired, please manually set 'output_key'.\n",
      "  warnings.warn(\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py --server.headless true --server.port 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsFStNFJKPxL"
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ilA0-5tAKPa1",
    "outputId": "e47c7e18-1608-4b5c-9e96-49de1c5e2985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain: 0.3.23\n",
      "langchain-core: 0.3.51\n",
      "langchain-openai: 0.3.16\n",
      "langchain-anthropic: 0.3.12\n",
      "langchain-huggingface: 0.1.2\n",
      "anthropic: 0.50.0\n",
      "openai: 1.76.0\n",
      "transformers: 4.50.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-73c635b89714>:2: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "def show_versions(packages):\n",
    "    for pkg in packages:\n",
    "        try:\n",
    "            v = pkg_resources.get_distribution(pkg).version\n",
    "            print(f\"{pkg}: {v}\")\n",
    "        except:\n",
    "            print(f\"{pkg}: ❌ NOT INSTALLED\")\n",
    "\n",
    "show_versions([\n",
    "    \"langchain\",\n",
    "    \"langchain-core\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-anthropic\",\n",
    "    \"langchain-huggingface\",\n",
    "    \"anthropic\",\n",
    "    \"openai\",\n",
    "    \"transformers\"\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1Q9O_I6lVWfr"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03ec30550c29470a83120291b300d051": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e4800b9dc54400db252c005fff31cd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10acb10ba3704934a393d36832eef5e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1aa27883bacb4900870f0c2e87251a9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219e067868de41b49ce32c6639b8b31f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7a36135f77342228e6cda70745297e8",
      "max": 301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_261ad2f66c6441c3abd824d72ddb001a",
      "value": 301
     }
    },
    "22957721b1d0426eb66003b3db4ae473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efb49102d9b046a68d33676c74972cc5",
      "placeholder": "​",
      "style": "IPY_MODEL_d50d966a30d14e5ebac9611313e78b83",
      "value": " 2.47G/2.47G [00:09&lt;00:00, 265MB/s]"
     }
    },
    "250d6044e72a4d0fa05182140f691f4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3cef69820ce47b8a706fea0b912f0ef",
      "max": 843,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36eefd8844e14105b9836d0acbe995ee",
      "value": 843
     }
    },
    "261ad2f66c6441c3abd824d72ddb001a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26e26f766be64e569558e03ed1ed3079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c6637b455240ec83e5aaa5034dd357": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36eefd8844e14105b9836d0acbe995ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3cadd5dda7ac4070b30eefa05eca8c89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e74151d5161c49d7a0d9b4abcc9f6177",
      "placeholder": "​",
      "style": "IPY_MODEL_26e26f766be64e569558e03ed1ed3079",
      "value": " 185/185 [00:00&lt;00:00, 24.3kB/s]"
     }
    },
    "3fbef0af0dd945b296f6097a26a5b9b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4193eb1fd897470c94bcac1d3f396eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebb31c74fbe24b469006ac24ecf26a77",
      "placeholder": "​",
      "style": "IPY_MODEL_66ac81ee59214838b5bb07ad1fe949ca",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4971cca062084016b59f682c3511b22c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a56ff10e48042389c93be00559a51ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9623676312454e378fbd33d0ab120c68",
       "IPY_MODEL_219e067868de41b49ce32c6639b8b31f",
       "IPY_MODEL_b690f556381f42ad81389342048598ac"
      ],
      "layout": "IPY_MODEL_03ec30550c29470a83120291b300d051"
     }
    },
    "546383cf6ab345a5bd903ac3b6214330": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64529799d6af434a92a7a874fd4eaeec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df69d050eb66401480ed4682b108750a",
       "IPY_MODEL_250d6044e72a4d0fa05182140f691f4c",
       "IPY_MODEL_df8c5805cc714ceeb17e57cd751d69b7"
      ],
      "layout": "IPY_MODEL_aacede47dccb4b599e23ea17c7f5a60f"
     }
    },
    "66ac81ee59214838b5bb07ad1fe949ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a0a797621314b28a7bbb52c2294f511": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f965e091aa424c6e8ff69b7946442eff",
      "max": 185,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b681f2dd85f54a509d75df399fbfc127",
      "value": 185
     }
    },
    "7044eb78fd00424d8563eb9eac181479": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10acb10ba3704934a393d36832eef5e1",
      "placeholder": "​",
      "style": "IPY_MODEL_1aa27883bacb4900870f0c2e87251a9e",
      "value": "tokenizer.json: 100%"
     }
    },
    "74bc569a765e4420a9a7ffc5fac926d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77831da0381247b5948c9f89d07b6356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82adc7cbc5444c0a8ffef89eb6058e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "836f417e8282420d974cece602d28bcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f7c5df453224149ab470ece1273f8a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9110260092714ac680b2914b157a01c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_836f417e8282420d974cece602d28bcf",
      "placeholder": "​",
      "style": "IPY_MODEL_d857aee4d742474c866e73dc113c2c9e",
      "value": "model.safetensors: 100%"
     }
    },
    "922bf9238db6488c9db352836e59ce78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_965b25fe627f4562928835e7c3db8486",
      "placeholder": "​",
      "style": "IPY_MODEL_b7ed6631145943d6a4af7107c43e54d5",
      "value": " 50.5k/50.5k [00:00&lt;00:00, 4.77MB/s]"
     }
    },
    "947582de69d84d66bea8c0dfcb5fac63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9623676312454e378fbd33d0ab120c68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_947582de69d84d66bea8c0dfcb5fac63",
      "placeholder": "​",
      "style": "IPY_MODEL_77831da0381247b5948c9f89d07b6356",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "965b25fe627f4562928835e7c3db8486": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c754fbec3dc4838934a9805fa0ac524": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7044eb78fd00424d8563eb9eac181479",
       "IPY_MODEL_ed883e6363ed4a11b7fef5dfe57cbdbf",
       "IPY_MODEL_c9730f77a54e43b88770cec4b0387d2c"
      ],
      "layout": "IPY_MODEL_546383cf6ab345a5bd903ac3b6214330"
     }
    },
    "a17ef2fabafa4727bb3b04ab22f61cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e25ddd35e25944599127aebdc31659cb",
      "max": 2471645608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4971cca062084016b59f682c3511b22c",
      "value": 2471645608
     }
    },
    "a3cef69820ce47b8a706fea0b912f0ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aacede47dccb4b599e23ea17c7f5a60f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab32ccea70844ebe935cafa934042dc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad1ed2a7b6d24443a67c885d911ff3aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9110260092714ac680b2914b157a01c3",
       "IPY_MODEL_a17ef2fabafa4727bb3b04ab22f61cf7",
       "IPY_MODEL_22957721b1d0426eb66003b3db4ae473"
      ],
      "layout": "IPY_MODEL_e56e53f1657544589046df1a22c28a51"
     }
    },
    "b1e987f1fa334900a11d433aaf897070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b643418c54074ed5bf4530411873a92e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b681f2dd85f54a509d75df399fbfc127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b690f556381f42ad81389342048598ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de8d1f32357142259e338db0932a5264",
      "placeholder": "​",
      "style": "IPY_MODEL_fe2adf161a2d4f63a75dc984e5813b42",
      "value": " 301/301 [00:00&lt;00:00, 38.0kB/s]"
     }
    },
    "b6b8019ccb4642b7bd830cd4f0aa6b60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f7c5df453224149ab470ece1273f8a2",
      "max": 50500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6b23560f59e452c9b31bae652e20f0e",
      "value": 50500
     }
    },
    "b7ed6631145943d6a4af7107c43e54d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9730f77a54e43b88770cec4b0387d2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5fc4634281647be8374435e9ae5518a",
      "placeholder": "​",
      "style": "IPY_MODEL_b1e987f1fa334900a11d433aaf897070",
      "value": " 9.09M/9.09M [00:00&lt;00:00, 50.0MB/s]"
     }
    },
    "ce02ac3e2db74a99a1f35fb552cb3390": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d50d966a30d14e5ebac9611313e78b83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5fc4634281647be8374435e9ae5518a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d857aee4d742474c866e73dc113c2c9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dca996d4075a40a0a96fa0c52ba65db7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de8d1f32357142259e338db0932a5264": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df69d050eb66401480ed4682b108750a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3fbef0af0dd945b296f6097a26a5b9b3",
      "placeholder": "​",
      "style": "IPY_MODEL_b643418c54074ed5bf4530411873a92e",
      "value": "config.json: 100%"
     }
    },
    "df8c5805cc714ceeb17e57cd751d69b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74bc569a765e4420a9a7ffc5fac926d2",
      "placeholder": "​",
      "style": "IPY_MODEL_0e4800b9dc54400db252c005fff31cd2",
      "value": " 843/843 [00:00&lt;00:00, 96.0kB/s]"
     }
    },
    "e25ddd35e25944599127aebdc31659cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e56e53f1657544589046df1a22c28a51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e74151d5161c49d7a0d9b4abcc9f6177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebb31c74fbe24b469006ac24ecf26a77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed883e6363ed4a11b7fef5dfe57cbdbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dca996d4075a40a0a96fa0c52ba65db7",
      "max": 9085657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7ae1e526cda4076a2038e46d612607e",
      "value": 9085657
     }
    },
    "edcb7ae4fd7e43f4bae7b7f020594f79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce02ac3e2db74a99a1f35fb552cb3390",
      "placeholder": "​",
      "style": "IPY_MODEL_82adc7cbc5444c0a8ffef89eb6058e9b",
      "value": "generation_config.json: 100%"
     }
    },
    "efb49102d9b046a68d33676c74972cc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6b23560f59e452c9b31bae652e20f0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f7a36135f77342228e6cda70745297e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7ae1e526cda4076a2038e46d612607e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f965e091aa424c6e8ff69b7946442eff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd5fc14894d04b18ac6c13d420d9ad80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_edcb7ae4fd7e43f4bae7b7f020594f79",
       "IPY_MODEL_6a0a797621314b28a7bbb52c2294f511",
       "IPY_MODEL_3cadd5dda7ac4070b30eefa05eca8c89"
      ],
      "layout": "IPY_MODEL_35c6637b455240ec83e5aaa5034dd357"
     }
    },
    "fe2adf161a2d4f63a75dc984e5813b42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffbab6e7401e441fa0df143ac971266e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4193eb1fd897470c94bcac1d3f396eb6",
       "IPY_MODEL_b6b8019ccb4642b7bd830cd4f0aa6b60",
       "IPY_MODEL_922bf9238db6488c9db352836e59ce78"
      ],
      "layout": "IPY_MODEL_ab32ccea70844ebe935cafa934042dc0"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
